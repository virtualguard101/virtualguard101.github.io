[{"title":"3BodySimulator：Python & C++ 项目标准化构建","url":"/2025/05/23/3BodySimulator/","content":"\n## 导言\n近期刚刚结束[CS106L | Standard C++ features and syntax](https://web.stanford.edu/class/cs106l/)的学习，想借此机会完善一下对C++项目构建的学习，如`CMake`等构建工具的使用，故立此项。\n\n通过本次项目你会了解到：\n\n- 1. C++项目标准化基础\n\n- 2. `CMake`、`vcpkg`等C++构建工具的基本使用\n\n- 3. 多语言配合构建（C++ & Python）\n\n下面是完成此次项目所需的基本条件：\n\n- C++ 编译器\n\n- [Git](https://git-scm.com/)：版本控制\n\n- [CMake(*>= v3.22*)](https://cmake.org/documentation/)：C++构建工具\n\n- [vcpkg](https://learn.microsoft.com/zh-cn/vcpkg/)：C++包管理工具\n\n- [Python(*>= v3.12*)](https://www.python.org/)：可视化模块\n\n- [uv](https://docs.astral.sh/uv/)：Python包管理工具\n\n文中的构建平台为**Ubuntu22.04**\n\n此次项目注重C++项目的标准化以及构建工具（`vcpkg`、`CMake`）的使用，代码逻辑部分主体由`DeepSeek`、`ChatGPT`等AI大模型完成。\n\n- 项目仓库：[3BodySimulator](https://github.com/virtualguard101/3BodySimulator)\n\n## 初始化项目\n\n首先使用两个语言的包管理器分别对项目进行初始化：\n\n### `vcpkg`\n\n```bash\nvcpkg new --application\n```\n\n对生成的`vcpkg.json`进行配置：\n\n```json\n{\n    \"name\": \"three-body-simulator\",\n    \"version-string\": \"0.1.0\",\n    \"dependencies\": [\n        {\n            \"name\": \"python3\",\n            \"version>=\": \"3.12.9\"\n        },\n        \"pybind11\"\n    ],\n    \"builtin-baseline\": \"a337f5fe100f83026072765ea63a8776f984f6fd\"\n}\n```\n\n>注意所有键值对的内容只能包含**小写字母**，否则后续构建时会报错。\n\n### `uv`\n\n```bash\nuv init\n```\n\n将项目信息写入`pyproject.toml`\n```js\n[project]\nname = \"3BodySimulator\"\nversion = \"0.1.0\"\ndescription = \"The visualization simulation of three-body motion implemented using C++ & Python.\"\nreadme = \"README.md\"\nrequires-python = \">=3.12\"\ndependencies = [\n    \"matplotlib>=3.8.0\",\n    \"ninja>=1.11.1\",\n    \"numpy>=1.26.0\",\n    \"pybind11>=2.11.1\",\n    \"pygame>=2.6.1\",\n]\n```\n\n随后去除无用的生成配置即可。\n\n随后对项目结构初始化：\n\n### 项目结构\n```bash\n.\n├── build.sh              # build shell script\n├── CMakeLists.txt        # CMake build config(outer)\n├── CMakePresets.json     # vcpkg CMake toolchain config(public)\n├── CMakeUserPresets.json # vcpkg CMake toolchain config(private)\n├── LICENSE\n├── pyproject.toml        # Python project config\n├── python                # Python script folder\n│   ├── dynamic.py\n│   ├── example.json      # example input json data\n│   ├── pyonly.py\n│   └── visualize.py\n├── README.md\n├── requirements.txt      # Python dependencies\n├── src                   # C++ source folder\n│   ├── CMakeLists.txt    # CMake build config(inner)\n│   ├── three_body.cpp\n│   └── three_body.h\n├── uv.lock\n├── vcpkg-configuration.json\n└── vcpkg.json            # vcpkg dependencies config\n```\n\n## 代码实现\n\n这部分并不是我们本次项目的重点，故使用了大语言模型（[chatGPT](https://chatgpt.com/)）负责该部分的实现与完善。~~绝对不是我想偷懒😋~~\n\n其中采用的技术栈在项目的[README](https://github.com/virtualguard101/3BodySimulator?tab=readme-ov-file#tech-stack-in-this-project)中有详细的总结。后续会视情况完善对这一部分的学习和解构。\n\n在实现的代码源文件中，我们使用C++作为**底层物理引擎**的构建语言，使用Python作为**主程序语言**并负责**可视化与用户交互**。二者的源文件分别位于项目根目录的`src`和`python`文件夹下。\n\n## 项目构建\n\n接下来进入本项目的重点。\n\n创建本次项目的主要目的是为学习**CMake**和**vcpkg**的基本使用，故将项目构建配置的部分视为重点。\n\n本项目使用`CMake` & `vcpkg`工具链进行C++的构建，使用`uv`进行Python的依赖与项目管理，可遵循『**获取依赖→配置→编译→虚拟环境运行**』的流程对项目进行构建与测试运行：\n\n### 获取依赖\n\n类似Python的`pip`，`vcpkg`是一个相对简单易用的cpp包管理工具（虽然但是各种配置还是让人用的很难受🙃，毕竟C++的生态就这样），在该项目中，我们将使用它相对容易地获取项目所需的相关依赖。\n\n安装就不再赘述，详情参考[官方文档](https://learn.microsoft.com/zh-cn/vcpkg/)，注意记住自己安装的路径，以便后续工具链的配置。\n\n- 编辑依赖列表\n\n在本项目中，我们选择使用C++配合Python完成模拟实现。chatGPT给出的实现思路是**使用cpp实现天体运动的底层物理引擎，构建输出一个Python可直接调用的共享库（`.so`/`.pyd`），然后由Python在可视化实现中直接调用**。\n\n因此，在C++模块的实现中，我们需要使用[pybind11](https://pybind11.readthedocs.io/en/stable/basics.html)联系二者。\n\n>`pybind11`是一个轻量级的库，用于将C++代码绑定到Python中，使得Python能够调用cpp的高性能代码。\n\n为了引入`pybind11`，我们就需要通过配置`vcpkg.json`的依赖列表使得后续运行构建时能够导入它。\n\n在**初始化项目**的过程中，我们已经对`vcpkg.json`进行了配置。是的，那就是所谓的**依赖列表**。根据[官方文档](https://learn.microsoft.com/zh-cn/vcpkg/get_started/get-started?pivots=shell-bash#3---add-dependencies-and-project-files)的描述，也可通过`port`命令添加依赖：\n```bash\nvcpkg add port pybind11\n```\n\n### 构建配置\n\n这是该项目中最为重要的一步，主要的工作简单来说就是配置`CMakeLists.txt`。\n\n由于我们使用了第三方工具`vcpkg`作为包管理工具，合理配置这二者之间的工具链关系就尤为关键。\n\n我们配置的思路是，在项目的根目录和用于存放C++模块的`src`中分别创建一个`CMakeLists.txt`。前者用于配置CMake在构建过程中与vcpkg的工具链参数；后者则专门用于配置cpp模块的构建逻辑。\n\n由此便有了以下配置：\n\n`CMakeLists.txt`:\n```bash\n# 项目基本参数\ncmake_minimum_required(VERSION 3.20)\nproject(3BodySimulator LANGUAGES CXX)\n\n# 使用 vcpkg 的 Toolchain\nif(NOT DEFINED CMAKE_TOOLCHAIN_FILE)\n  set(\n    CMAKE_TOOLCHAIN_FILE \"~/vcpkg/scripts/buildsystems/vcpkg.cmake\"\n    DPython3_EXECUTABLE=$(which python)\n    DCMAKE_BUILD_TYPE=Release\n    CACHE STRING \"\"\n  )\nendif()\n\n# 把 src 子目录加入构建\nadd_subdirectory(src)\n```\n\n`src/CMakeLists.txt`:\n```bash\n# 查找 pybind11（由 vcpkg 安装并集成）\nfind_package(pybind11 CONFIG REQUIRED)\n\n# 源文件列表\npybind11_add_module(three_body\n  three_body.cpp\n)\n\n# 设置头文件路径\ntarget_include_directories(three_body\n  PRIVATE ${CMAKE_CURRENT_SOURCE_DIR}\n)\n\n# 设置 C++17 标准\ntarget_compile_features(three_body PUBLIC cxx_std_17)\n\n# 把生成的共享库 (.so/.pyd) 放到 ../python 目录\nset_target_properties(three_body PROPERTIES\n  LIBRARY_OUTPUT_DIRECTORY ${CMAKE_SOURCE_DIR}/python\n  OUTPUT_NAME \"three_body\"    # 忽略 ABI tag，统一输出 three_body.so\n  PREFIX \"\"                   # 无前缀\n  SUFFIX \".so\"                # 强制后缀 .so\n)\n```\n\n正常情况下，按照以上构建配置，只需执行如下命令即可进行C++模块的构建生成与编译：\n```bash\n# 配置生成\ncmake --preset=vcpkg\n# 编译生成.so\ncmake --build build/\n```\n\n如果不出意外的话，cmake会在`python`路径下生成一个名为`three_body`的`.so`共享库（为了方便调用，故将共享库生成到与py脚本相同的目录下）。事实上，到这里，我们的项目就可以直接通过`python`命令直接运行了（当然，前提是你的Python依赖没有问题）。\n\n~~uv：世界，遗忘我...🙃~~\n\n### `uv`Python虚拟环境配置\n\n虽然完成了C++模块的构建工作基本就意味着项目能够跑起来了，但Python混乱的环境依赖问题在某些时候是出了名的让人头痛。为了避免这一情况，我们需要创建一个虚拟环境来运行我们的项目，为此，我们选择了[uv](https://docs.astral.sh/uv/)作为该项目的Python包管理器。\n\n>`uv`是一个由`Rust`编写的高性能Python包管理工具，其安装速度比传统工具要快上不少，同时还支持并行安装。\n>\n>更重要的是，它提供了一种十分便捷和强大的**项目依赖管理**与**虚拟环境管理**方式。\n\n在初始化项目的过程中，我们已经使用其进行了项目信息的初始化配置，接下来，我们将继续使用它轻松地配置和运行我们的项目：\n\n- 创建Python虚拟环境并激活\n```bash\nuv venv .venv         # 默认为系统 Python3.12\nsource .venv/bin/activate\n```\n\n- 在虚拟环境中安装依赖\n```bash\nuv pip install -r requirements.txt\n```\n\n安装好依赖后，我们就可以在虚拟环境中完美地运行我们的项目了：\n```bash\nuv run python/dynaminc.py\n```\n\n### 自动化构建脚本\n\n说了这么一堆，有人可能要问了：这么多的构建命令，还挺麻烦的，而且如果不小心搞乱了不就完犊子了？难道就没有方便的构建方式吗？\n\n有的兄弟，有的。\n\n事实上，我们上面讲解的构建顺序本身就有点问题：\n\n如果观察仔细的话，应该会注意到，前文中根目录下的`CMakeLists.txt`中在配置工具链时指定了一个名为`DPython3_EXECUTABLE`的参数，这个参数的功能是显式指定运行Python脚本的Python解释器，作用是强制保持运行环境的Python版本一致性。如果你在系统上使用与`uv`配置中Python版本不一致的解释器，且没有在构建C++模块前创建并激活Python虚拟环境，那么你在尝试运行项目时就会得到类似下面的报错信息：\n```bash\nTraceback (most recent call last):\n  File \"/home/virtualguard/projects/researching/cpp-engine/3BodySimulator/python/visualize.py\", line 11, in <module>\n    from three_body import Body, step\nImportError: Python version mismatch: module was compiled for Python 3.10, but the interpreter version is incompatible: 3.12.9 (main, Feb 12 2025, 14:50:50) [Clang 19.1.6 ].\n```\n\n对于这个问题，我们就需要通过强制规范构建顺序来保证项目自始至终是在我们创建的虚拟环境中构建并运行的，以确保项目环境的一致性；结合前面提到的“方便地构建方法”，我们就可以将众多的构建命令依序整合到一个`bash`脚本中，也就是所谓的**自动化构建脚本**：\n\n`build.sh`:\n```bash\n#!/bin/bash\nset -e\n\n#———————————————\n# 1. 清理旧构建\n#———————————————\necho \"清理旧构建文件...\"\nrm -rf build python/three_body* .venv/ vcpkg_installed/ vcpkg/\n\n#———————————————\n# 2. 创建并激活 uv 虚拟环境（Python 3.12）\n#———————————————\necho \"创建并激活 Python 3.12 虚拟环境...\"\nuv venv .venv         # 默认为系统 Python3.12\nsource .venv/bin/activate\n\n# 安装 Python 可视化脚本依赖\nuv pip install -r requirements.txt\n\n#———————————————\n# 3. 用 venv 中的 Python 配置 & 编译 C++ 扩展\n#———————————————\necho \"配置 CMake（指向 venv 中的 python）...\"\n# cmake -B build \\\n#   -DCMAKE_TOOLCHAIN_FILE=~/vcpkg/scripts/buildsystems/vcpkg.cmake \\\n#   -DPython3_EXECUTABLE=$(which python) \\\n#   -DCMAKE_BUILD_TYPE=Release\n\ncmake --preset=vcpkg\n\necho \"开始编译 C++ 扩展...\"\ncmake --build build\n\n#———————————————\n# 4. 检查生成结果\n#———————————————\necho \"生成的 Python 模块：\"\nls -l python/ | grep three_body\n\n#———————————————\n# 5. 运行可视化脚本\n#———————————————\necho \"执行 uv run python/visualize.py 启动三体模拟...\"\necho \"执行 uv run python/dynamic.py 启动动态模拟...\"\n```\n\n首先为脚本添加运行权限：\n```bash\nchmod +x build.sh\n```\n\n随后就可以直接通过脚本进行自动化构建了：\n```bash\n./build.sh\n```\n\n此时由于项目环境独立于系统全局的Python环境，构建运行均基于这个虚拟环境，确保了环境的一致性，也就不会出现像上面的环境冲突问题了。\n","tags":["C++","Python","vcpkg","CMake"],"categories":["Projects","Tools"]},{"title":"容器化技术与云技术","url":"/2025/05/19/container-tech/","content":"\n- [深入高可用系统原理与设计](https://www.thebyte.com.cn/)\n","tags":["云计算","计算机网络"],"categories":["Tools","Useful Stack"]},{"title":"Arch Linux安装要点记录","url":"/2025/05/19/arch-linux/","content":"\nArch Linux是一个支持高度定制化的Linux发行版，其采用滚动更新的方式对系统进行更新，更新策略激进，适合愿意花时间在自己系统的计算机用户或喜欢折腾的计算机用户。\n\n这里需要特别说明一点，在安装之前，需要反思自己是否真的适合使用Arch！否则Arch的高度定制化与激进的更新策略将会使你陷入极大的麻烦！毕竟高度定制化的代价就是你需要为系统付出比其他稳定发行版多得多的时间去维护它。\n\n## 基本安装\n\n针对这部分内容，教程[Arch Guide | Nakano Miku](https://arch.icekylin.online/guide/)有详尽的阐述，包括从安装准备到系统美化的所有内容。\n\n这里记录几个我在真机安装过程中遇到的问题。\n\n### 格式化EFI分区前未备份原有系统启动引导（双系统）\n\n我在安装过程中由于急于求成，在为EFI分区扩容时未备份原有系统（这里是Win11）的启动引导程序就直接将其格式化了，结果安装完Arch的基本系统才发现Win11进不去了.....\n\n虽说安装前有备份Win11的系统映像，但为了一个EFI分区动用这个实属大材小用，因为基本数据的分区并没有任何问题。在这个问题上，我选择使用WinPE镜像系统对Win11的启动引导进行还原。只需准备一个装有WinPE镜像的U盘，启动进入WinPE，按照下图的提示，选择修`UEFI`引导进行修复即可：\n\n![](https://i.imgur.com/8fTXOCP.jpeg)\n\n### 输入法异常\n\n这在教程[Arch Guide | Nakano Miku](https://arch.icekylin.online/guide/)有提示，（如果是按照此教程进行的安装）执行命令`fcitx5-diagnose`进行问题诊断并按照输出提示修复即可。\n\n## 在可移动设备安装\n\n该部分可参考[将Arch Linux系统安装在可移动设备上的要点 | ToBeHonest's BLOG](https://b2og.com/archives/23)。\n\n第一次安装中，我就将Arch装在了一个256G、使用USB3.1的U盘上，同时由于使用[虚拟机](https://arch.icekylin.online/guide/rookie/pre-virt.html)运行安装镜像，所以并没有碰到什么大问题。\n\n---\n**[参考文献]：**\n\n- [在可移动设备上安装 Arch Linux | Arch Wiki](https://wiki.archlinuxcn.org/zh-sg/%E5%9C%A8%E5%8F%AF%E7%A7%BB%E5%8A%A8%E8%AE%BE%E5%A4%87%E4%B8%8A%E5%AE%89%E8%A3%85_Arch_Linux)\n\n- [将Arch Linux系统安装在可移动设备上的要点 | ToBeHonest's BLOG](https://b2og.com/archives/23)\n\n- [Arch Guide | Nakano Miku](https://arch.icekylin.online/guide/)\n\n- [ArchLinuxTutorial | Arch Linux Studio](https://archlinuxstudio.github.io/ArchLinuxTutorial/#/)\n","tags":["Linux"],"categories":["Tools"]},{"title":"docker-compose + nginx快速构建个人站点","url":"/2025/04/26/web-build/","content":"\n## 导言\n\n起因是我决定搭建一个个人站点用于模块化整合资源，在搜罗主页主题时因为部署简单相中了[remio-home | kasuie](https://github.com/kasuie/remio-home)，有多简单呢？简单到只需要进行一些及其简单的配置（cv大法可用）后，在服务器上输入一行`docker-compose up -d`即可。结合大佬的一些建议和我自己的一些~~偷懒~~自动化的想法，便有了下文。\n\n如题，本文主要讲解如何从零开始在一台云服务器上利用docker-compose + nginx快速构建一个个人站点。得益于强大的现代化工具链以及开源社区的支持，我们完成这个简易项目所需的计算机理论基础并不多，甚至可以说是几乎为零，只需要知道文档应该怎么读，如何正确打开开发中的“cv大法”来为自己的自动化工具链编写配置文件。当然，最好有一点web开发的基础，这样在遇到意料之外的问题时不至于束手无策。\n\n通过该项目你会了解到以下内容：\n\n- **1. 远程服务器的基础使用**  \n- **2. docker、docker-compose部署服务的基础操作**  \n- **3. web开发实现原理基础——静态资源部署**  \n- **4. hexo静态网页生成工具的使用**  \n- **5. Github Action配置自动化部署**  \n- **6. nginx基础配置（反向代理、二级域名）**  \n- **7. 在容器内使用certbot申请ssl证书，并通过定时任务自动化续签**\n\n下面是完成该项目所需的基础条件：\n\n- 一台服务器\n- 一个有效域名\n\n**服务器**可在云服务器运营商处租用。国内比较可靠的运营商有阿里云、腾讯云等。\n\n**域名**同样需要在运营商购买，也可通过特殊手段申请免费域名（不过免费申请的域名如有人出钱购买就会被回收）。获得域名后根据DNS云解析平台的文档进行解析配置即可。\n\n## 准备工作\n\n### 部署环境\n服务器的初始配置可参考这篇文章[远程服务器的基础使用](https://note.virtualguard101.xyz/notes/%E5%B7%A5%E5%85%B7/ssh/)，这里不再赘述。由于需要使用`docker`进行部署，我们需要先在服务器上安装一下docker。通过以下命令安装：\n\n```bash\ncurl -fsSL https://get.docker.com | bash -s docker\nsudo apt install docker-compose\n```\n\n将当前用户添加到docker用户组：\n\n```bash\nsudo groupadd docker # 若尚不存在 docker 组，则需先创建\nsudo usermod -aG docker $USER\n```\n\n由于是通过容器部署服务，环境处于“隔离”状态，`nginx`无需下载安装，可通过镜像运行于容器中。\n\n### 主页测试部署\n\n首先挑选一个能够使用docker部署的web主页，这里我们以[remio-home | kasuie](https://github.com/kasuie/remio-home)为例。根据文档进行配置与部署，部署完成后访问对应端口，观察配置是否生效。\n\n按照主题文档配置完`docker-compose.yml`后，将宿主机的端口改为80（http默认端口），`docker-compose down && docker-compose up -d` 或 `docker-compose restart` 重启服务，通过外网设备进行访问，正常情况下和本地访问结果无异。也可通过端口转发在本地主机进行测试访问，具体这里不展开。\n\n在通过外网设备进行访问时，若先前配置了DNS云解析，可通过域名进行访问。\n\n## 静态网页资源测试\n\n### hexo基础使用\n互联网中有着数不胜数的静态网页生成工具，这里我们使用[hexo](https://hexo.io/zh-cn/)。\n\n首先进入[主题选择页](https://hexo.io/themes/)选择几个心仪的主题，随后根据主题文档和官方文档构建静态站点目录和安装依赖。然后还是各个配置文件的修改与测试，这个过程相对枯燥且繁琐。\n\n需要注意的是，有些主题在后面的部署过程中可能会出现各种各样的兼容性问题，遇到无法暂时解决的，可以更换主题。\n\n配置完主题后，通过`hexo s`命令测试生成静态网页，通过浏览器访问`localhost:4000`生成网页，查看是否符合预期。确认无误后，即可进入部署阶段。\n\n## 部署\n\n### Github Page + 用户自定义域名\n\n有Github Page静态网页部署经验的同志对此应该不陌生，配合hexo的[一键部署](https://hexo.io/zh-cn/docs/one-command-deployment)使用起来方便到不能再方便了，详情这里不再展开。针对此部署方法，就算不想看官方文档，网络上也有数不胜数的教程。\n\n这种部署方法固然方便，但只能部署（.github.io）或绑定到一个域名下（custom domain），若想要通过多个二级域名来分隔部署web资源，或是将来可能需要部署其他无法通过Github Page来部署的服务（如用户登陆服务、数据库服务等），这样的方法就会极大地限制web服务的可扩展性。简单来说，是否选择该部署方法取决于部署需求，确认只有存放静态资源的需求则该方法操作便捷且功能绰绰有余。\n\n### docker-compose + nginx\n\n废话说了这么多，接下来正片开始。\n\n在现代 web 开发中，使用 Nginx 代理不同的子域名到相应的 web 项目是一个常见的需求。同时，为了使我们的web服务能够与使用docker容器部署的主页处于同一个服务端口上，我们就需要把处于不同容器的web服务通过docker-compose合成为一个，并映射到宿主机的80端口上以供外界访问。\n\n看上去很复杂，但事实上，由于我们并不需要了解容器内的服务具体在做些什么，理论上，我们只需要简单了解docker的工作原理以及`docker-compose.yml`和`nginx.conf`的配置规则即可实现前文提到的**一键部署**。\n\n当然，缺点也很明显：根域名（主页）和各二级域名（web服务）均需要通过nginx进行转发，且“处于一条绳上”，一旦nginx的配置或是其本身出现问题，所有写在配置里的服务就直接给一锅端了。\n\n~~当然这也契合部分人开（摸）发（鱼）习惯，很喜欢容器化开发者中流传的一句话：“我就喜欢配一天环境啥也不干的感觉☝🤓”~~\n\n两个配置文件的编写上，如果是单纯的多个二级域名的配置，网络上的教程一抓一大把，但我们的这个项目的难点就在于此，因为我们还要把先前就已成功部署的主页服务也融合进来，如何正确将它们配置到同一个端口上对于不熟悉docker和第一次接触nginx的人算的上是个挑战（比如我）。\n\n然而经过一段时间的尝试（AI+），我们就能发现这并非什么难事：\n\n#### docker配置\n\n以下配置模板仅供参考\n\n```yml\nversion: \"3.8\"\n\nservices:\n  remio-home:\n    image: kasuie/remio-home\n    container_name: remio-home\n    ports:\n      - \"8080:3000\"\n    environment:\n      - GTMID=.....\n      - PASSWORD=.....\n      - AMAP_KEY=.....\n    volumes:\n      - ./remio-home/config:/remio-home/config\n      - ./remio-home/icons:/remio-home/public/icons\n      - ./remio-home/fonts:/remio-home/public/fonts\n    networks:\n      - web_network\n    restart: unless-stopped\n\n  nginx:\n    image: nginx:latest\n    container_name: nginx\n    ports:\n      - \"80:80\"\n      # - \"443:443\"\n    volumes:\n      - ./nginx/conf.d/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/log:/var/log/nginx\n      # - ./certbot/www:/usr/share/certbot/www:ro\n      # - ./certbot/ssl:/etc/letsencrypt:ro\n    depends_on:\n      - subsite1\n      - subsite2\n      - subsite3\n    networks:\n      - web_network\n    command:  nginx -g 'daemon off;'\n\n  # certbot:\n  #   container_name: certbot\n  #   image: certbot/certbot\n  #   volumes:\n  #     - ./certbot/www:/usr/share/certbot/www:rw #http验证目录，可设置rw可写，与nginx容器对应的宿主机目录时一致的\n  #     - ./certbot/ssl:/etc/letsencrypt:rw #证书位置，同上，注意不要只映射到live，而是它的上一级\n\n  subsite1:\n    image: nginx:latest\n    container_name: subsite1\n    volumes:\n      - ./sub-sites/subsite1/public:/usr/share/nginx/html\n    networks:\n      - web_network\n\n  subsite2:\n    image: nginx:latest\n    container_name: subsite2\n    volumes:\n      - ./sub-sites/subsite2/public:/usr/share/nginx/html\n    networks:\n      - web_network\n\n  subsite3:\n    image: nginx:latest\n    container_name: subsite3\n    volumes:\n      - ./sub-sites/subsite3/public:/usr/share/nginx/html\n    networks:\n      - web_network\n\nnetworks:\n  web_network:\n    driver: bridge\n\n```\n\ndocker配置的关键在于`volumes`，即**挂载卷**的路径配置。\n\n在nginx附属服务（二级域名）的配置中，挂载卷参数的`:`前填入的是需要挂载的宿主机路径，`:`后是容器内的映射路径。这里我们需要挂载的路径是各个二级域名下需要“展示”的**前端文件**，即前文中提到的由静态网页生成工具生成的**静态资源**。\n\n在hexo中，我们通常使用命令`hexo cl && hexo g`清理旧版本的静态文件并生成新版，生成的静态文件默认处于各项目根目录的`public`路径下。\n\n静态资源的整理可在任意主机上进行，部署时只需确保由静态网页生成的静态资源处于服务器上并挂载到容器的正确路径下即可。通常情况下，为确保隐私安全，静态文件的整理工作我们一般在本地主机上进行。在后续的章节中我们会介绍如何通过配置Github Action实现使静态文件从本地自动化部署至服务器上。\n\n#### nginx配置\n\n`nginx.conf`的配置是该项目的核心，若出现错误导致部署无法进行，70%的问题出在nginx上，而nginx的问题有80%出在配置上（数据是瞎编的😋，但问题是真的）。\n\n以下是`nginx.conf`的参考配置，受限于篇幅，只列举主页及其中的一个二级域名的配置：\n\n```conf\nevents {}\n\nhttp {\n    ; server {\n    ;     listen 80;\n    ;     # listen [::]:80;\n\n    ;     server_name  virtualguard101.xyz;#域名\n    ;     server_tokens off;\n\n    ;     #配置http验证可访问\n    ;     location /.well-known/acme-challenge/ {\n    ;         #此目录都是nginx容器内的目录，对应宿主机volumes中的http验证目录，而宿主机的又与certbot容器中命令--webroot-path指定目录一致，从而就整个串起来了，解决了http验证问题\n    ;         root /usr/share/certbot/www;\n    ;     }\n    ;     #http跳转到https\n    ;     location / {\n    ;         return 301 https://$host$request_uri;\n    ;     }\n    ; }\n\n    server {\n        listen 80;\n        server_name virtualguard101.xyz;\n\n        location / {\n            proxy_pass http://remio-home:3000;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }       \n        # 强制HTTPS重定向\n        # return 301 https://$host$request_uri;\n    }\n\n    ; server {\n    ;     listen 443 ssl http2;\n    ;     server_name virtualguard101.xyz;\n\n    ;     ssl_certificate /etc/letsencrypt/live/virtualguard101.xyz/fullchain.pem;\n    ;     ssl_certificate_key /etc/letsencrypt/live/virtualguard101.xyz/privkey.pem;\n\n    ;     location / {\n    ;         proxy_pass http://remio-home:3000;\n    ;         proxy_set_header Host $host;\n    ;         proxy_set_header X-Real-IP $remote_addr;\n    ;         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    ;         proxy_set_header X-Forwarded-Proto $scheme;\n    ;     }\n    ; }\n\n\n    ; server {\n    ;     listen 80;\n    ;     # listen [::]:80;\n\n    ;     server_name  projects.virtualguard101.xyz;#域名\n    ;     server_tokens off;\n\n    ;     #配置http验证可访问\n    ;     location /.well-known/acme-challenge/ {\n    ;         #此目录都是nginx容器内的目录，对应宿主机volumes中的http验证目录，而宿主机的又与certbot容器中命令--webroot-path指定目录一致，从而就整个串起来了，解决了http验证问题\n    ;         root /usr/share/certbot/www;\n    ;     }\n    ;     #http跳转到https\n    ;     location / {\n    ;         return 301 https://$host$request_uri;\n    ;     }\n    ; }\n\n    server {\n        listen 80;\n\n        server_name projects.virtualguard101.xyz;\n\n        location / {\n            proxy_pass http://projects:80;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n\n        # return 301 https://$host$request_uri;\n    }\n\n  ;   server {\n  ;       listen 443 ssl http2;\n  ;       server_name projects.virtualguard101.xyz;\n\n  ;       ssl_certificate /etc/letsencrypt/live/projects.virtualguard101.xyz/fullchain.pem;\n  ;       ssl_certificate_key /etc/letsencrypt/live/projects.virtualguard101.xyz/privkey.pem;\n\n  ;       location / {\n  ;           proxy_pass http://projects:80;\n  ;           proxy_set_header Host $host;\n  ;           proxy_set_header X-Real-IP $remote_addr;\n  ;           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n  ;           proxy_set_header X-Forwarded-Proto $scheme;\n  ;       }\n  ;   }\n  }\n```\n\nnginx配置的关键在于反向代理转发的配置，这是nginx一个十分重要的特性，利用它能够实现nginx中许多核心功能，如负载均衡、websocket代理等。对于我们目前的项目需求，暂时无需使用到这些较为复杂的功能，我们现在只需弄明白参数`proxy_pass`具体是做什么的，以及其最为基础的配置规则，剩下的交给cv大法即可。\n\n在nginx配置中，`proxy_pass`用于将客户端的请求代理到指定的后段服务器，简单理解就是把请求作了一次转发。其基础语法如下：\n\n```conf\nlocation /path/ {\n    proxy_pass http://backend_server:port;\n}\n```\n\n该配置会将客户端上的请求转发至运行在`port`端口上名为`backend_server`的服务。结合上面的配置模板进行理解，我们可以发现主页服务在前面的docker配置中我们“恰好”将其配置在了容器的`3000`端口上，而其他的二级域名（nginx服务）我们均将其配置在了容器的`80`端口上，那么在外网设备（客户端）通过域名访问对应服务时，nginx就会将访问请求转发到对应的端口上。\n\n那么nginx怎么知道客户发送了访问请求？这就是**监听**要做的事。http服务默认通过`80`端口访问，通过配置`listen`参数我们可以使nginx服务监听`80`端口，就像饭点食堂阿姨站在特定窗口等着你去打饭一样。\n\n配置模板中注释掉的模块是https的配置，由于我们还未申请ssl证书，现在只能先使用http。关于ssl证书的申请我们也会在后续的章节介绍。\n\ndocker 与 nginx的配置完成后，我们便可通过`docker-compose up -d`命令进行服务部署，此时正常情况下网页已经可以通过外网设备访问。若出现问题，一般情况下会反映在各个服务容器上，可通过`docker-compose logs`命令查看日志信息。\n\n## Github Action自动化部署\n\n~~作为一个懒人~~为了提高效率，写个自动化配置把部署的工作交给计算机来做自然是个不错的方法。Github Action为我们提供了一个简单的自动化构建平台，通过模块化的配置和与git远程仓库结合的管理方式极大简化了配置难度，同时集成了版本控制。\n\nGithub Action自动化的配置通常位于子站点项目根目录的`.github/workflows`下。由于自动化部署的方式多种多样，配置自然也同理，故以下配置模板仅供参考。\n\n```yml\nname: Deploy Subsite\n\non:\n  push:\n    branches: [main]\n\njobs:\n  hexo-build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        \n      - name: Setup Node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n          \n      - name: Install Dependencies\n        run: |\n          npm install -g hexo-cli\n          npm install\n        \n      - name: Build Site\n        run: hexo clean && hexo generate\n        \n      - name: Deploy to Server\n        uses: appleboy/scp-action@v0.1.7\n        with:\n          host: ${{ secrets.SERVER_IP }}\n          username: ${{ secrets.SERVER_USER }}\n          key: ${{ secrets.SSH_KEY }}\n          source: \"public/*\"\n          target: \"/home/<user>/sub-sites/<subsites_dir>/\"\n          \n      # - name: Refresh Nginx\n      #   uses: appleboy/ssh-action@v1.0.0\n      #   with:\n      #     host: ${{ secrets.SERVER_IP }}\n      #     username: ${{ secrets.SERVER_USER }}\n      #     key: ${{ secrets.SSH_KEY }}\n      #     script: |\n      #       docker exec nginx_main nginx -s reload\n```\n\n配置模板中，`Deploy to Server`模块是配置中较为核心的模块。该模块利用**scp**工具将生成的静态文件传送至站点服务器的指定路径下，其中的以`secrets`开头的三个变量分别是服务器的ip地址、用户与ssh私钥，通过仓库的`settings` >> `secrets and variables` >> `actions` 配置。\nssh私钥需在服务器上生成。\n\n通过上述自动化配置，在每次我们将本地仓库的更改推送至远程仓库时，github会自动在后台使用hexo生成静态文件，并通过scp将其发送至服务器的指定路径下。\n\n至此，我们仅需在本地的各个站点项目路径下修改配置或撰写文章，并将更改推送至github远程仓库，即可实现站点资源的自动化部署。\n\n## ssl认证与https模块配置（可选）\n\n经过上面五节的配置工作，我们的站点的雏形已经完成，接下来就是最后的收尾工作。关于ssl证书与https，尽管我们并不认为它是一个网页的必要组成部分，但我们还是强烈建议为自己的站点配置ssl证书与https模块以增强安全性与可扩展性。得益于[certbot](https://certbot.eff.org/)的ssl证书免费申请功能，我们已经能够较为容易地完成这项工作。\n\n### 首次申请ssl证书\n\n由于在该项目中，我们所有的服务均配置于docker容器中，因此我们同样需要将certbot的服务功能配置进docker-compose.yml中以实现后续的ssl证书自动化续签。事实上，certbot官方是不建议使用docker作为certbot的服务载体的，详情可参考[Get Certbot with Docker](https://eff-certbot.readthedocs.io/en/stable/install.html#alternative-1-docker)\n\n在配置前，首先需要拉取certbot的docker镜像：\n\n```bash\ndocker pull certbot/certbot\n```\n\n随后将前文中`docker-compose.yml`中`certbot`模块的注释去掉，并将nginx挂载卷中有关certbot的路径的注释去掉。启动服务，并通过以下命令进行测试申请：\n\n```bash\n# --dry-run是只测试不实际生成; --webroot-path对应着certbot内的http验证目录;-d后面是域名;--rm是运行后接着删除，certbot容器不需要一直开启，只是启动下生成证书即可\ndocker compose run --rm  certbot certonly --webroot --webroot-path /usr/share/certbot/www/ --dry-run -d [your_domain]\n```\n\n按照提示输入邮箱信息，若返回结果`The dry run was successful`，则说明测试成功，即可将`--dry-run`去掉以进行实际的证书获取：\n\n```bash\ndocker compose run --rm  certbot certonly --webroot --webroot-path /usr/share/certbot/www/ -d [your_domain]\n```\n\n申请成功后，可通过以下命令查看所有已申请的证书：\n\n```bash\ndocker compose run --rm certbot certificats\n```\n\n确认证书信息无误后即可开始nginx`https`模块的配置。与`docker-compose.yml`类似，将`nginx.conf`配置模板中https模块的注释去掉，同时将原来未注释的http模块注释掉，`docker-compose down && docker-compose up -d`重启服务。完成后通过外网设备访问网页，正常情况下，网址栏会显示该网页是安全的。\n\n### ssl证书自动化续签\n\n使用certbot一个很大的原因就是因为其可通过配置**定时任务**进行ssl证书的自动化续签。具体配置十分简单，一个bash的问题：\n\n创建bash脚本，并写入定时申请命令：\n\n```bash\nvim sslrenew.sh   # 创建脚本文件\n\n# 写入命令\ndocker compose run certbot renew\n```\n\n`crontab -e`添加定时任务，每个月第一天凌晨四点执行，也可根据自己情况进行配置：\n\n```bash\n0 4 1 * * ~/sslrenew.sh\n```\n\n配置完成后，可通过`crontab -l`命令查看配置的定时命令，确认配置是否写入。\n\n**BASE END**\n\n到此为止，所有的基础配置也就完成了。此时我们的个人站点已经可以被世界上所有接入互联网的设备访问了，同时我们也可根据个人需求为站点添加各种各样的功能与服务。\n\n主要参考文献：\n- [docker部署nginx多级子域名 | 蓝易云](https://cloud.tsyidc.com/web/822.html)\n- [docker部署certbot与nginx来获取ssl证书添加https及自动更新 | vishun](https://www.cnblogs.com/vishun/p/15746849.html)\n- [使用Certbot自签SSL证书 | kasuie](https://kasuie.cc/article/22)\n\n---\n\n## 增添服务\n\n既然我们都选择了使用云服务器来构建我们的个人站点，那么仅使用它来存放静态页面显然是大材小用。对于站点功能的丰富，还是那句话，在成熟工具链丰富的现代开发环境下，并不是什么很难的事情。很多时候，我们只需要正确打开别人写好的文档即可。\n\n对于功能扩展这部分的内容，更多的还是将目光放在部署工具供应者的使用文档上，这里只基于该文介绍的站点部署方法简单介绍一下我个人摸索出的**标准化部署流程**以及部署过程中可能碰到的**问题**。\n\n### 标准化部署流程\n\n以下流程为个人在实际部署过程中摸索出的不同服务部署过程的共通点，仅供参考。\n\n现在，假设我们想要在服务器上部署一个AI对话服务，那么我们便可遵循以下流程进行服务的配置及部署：\n\n#### 一、工具链选取及基础配置工作\n\n- **0. 选取对应的服务部署工具链，查阅官方文档并结合当前环境分析部署可行性。**\n\n我们想要在服务器上部署一个AI对话服务，那么结合当前部署环境，我们就应该在网络上查找对应的`docker`镜像（image）。这里我们使用[LLM Frontend | SillyTavern](https://github.com/SillyTavern/SillyTavern)进行部署。\n\n该框架具有docker镜像，且支持使用docker-compose部署，符合当前的环境要求，且部署难度和成本相对较低。\n\n- **1. 拉取docker镜像（可跳过）**\n\n执行以下命令以获取待部署的docker镜像：\n\n```bash\ndocker pull ghcr.io/sillytavern/sillytavern:latest\n```\n\n在使用docker-compose进行部署时，若`docker-compose.yml`配置无误，镜像会自动拉取。执行这一步主要是为了提前判定镜像是否处于可获取的状态。\n\n- **2. 根据工具文档及个人需求进行配置文件的配置或修改**\n\n项目主页：[SillyTavern - LLM Frontend for Power User](https://sillytavern.app/)\n项目仓库：[SillyTavern](https://github.com/SillyTavern/SillyTavern)\n\n#### 二、docker-compose.yml配置\n\n由于docker的容器环境是我们站点的部署基础，这部分的配置便显得尤为重要。可参考以下步骤进行配置：\n\n- **1. 依照文档给出的配置框架结合部署环境进行基础配置**\n\n官方给出的`docker-compose.yml`如下：\n\n```yml\nservices:\n  sillytavern:\n    build: ..\n    container_name: sillytavern\n    hostname: sillytavern\n    image: ghcr.io/sillytavern/sillytavern:latest\n    environment:\n      - NODE_ENV=production\n      - FORCE_COLOR=1\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - \"./config:/home/node/app/config\"\n      - \"./data:/home/node/app/data\"\n      - \"./plugins:/home/node/app/plugins\"\n      - \"./extensions:/home/node/app/public/scripts/extensions/third-party\"\n    restart: unless-stopped\n```\n\n我们可结合部署环境与部署需求对`environment`、`volumes`、`port`中的值进行修改，同时还需注意`docker-compose.yml`与服务自身配置（`config.yaml`）的对应关系。比如，针对`port`参数，`config.yaml`中默认将服务映射在`8000`端口上，若两个配置不对应，在访问时就会遇到`502(Bad Gateway)`错误。\n\n还有一点需要注意：由于nginx服务也运行于容器中，故在此项目的实际配置与部署过程中，真正有效的端口参数是`port`参数的**容器服务端口**。\n\n- **2. 网络关系配置**\n\n容器化技术的一大亮点在于不同服务容器环境相互独立的情况下也可通过形形色色的配置建立起各个容器间的联系。配置这些东西过程被厌恶容器技术的人所诟病，这些人认为该过程徒增工作复杂度，殊不知这是被他们所忽略的本职工作。\n\n服务间网络关系的配置也是上述关系配置中的一环，通过前文的配置我们知道，各个服务的网络配置通过`networks`参数控制，而在该项目中我们统一使用`web_network`作为各个服务的网络配置参数。故在官方文档原有框架的基础上，我们需要为模块追加如下配置：\n\n```yml\nnetworks:\n  - web_network\n```\n\n<!-- 否则会导致sillytavern容器未连接到web_network网络，出现容器错误 -->\n\n- **3. 服务依赖关系**\n\n和网络关系相比，不同服务的依赖关系在体现各个服务容器之间的联系上更加直接。\n\n在本项目中，由于需要使用nginx对各个服务进行转发，依赖关系便体现在各个部署在二级域名上的服务与nginx服务上。完成`sillytavern`服务的配置后，我们需要在nginx模块的`depend_on`参数追加如下配置：\n\n```yml\ndepend_on:\n  - .....\n  - sillytavern\n```\n\n<!--显式声明容器依赖关系，确保sillytavern先于nginx启动，否则会出现nginx容器错误 -->\n\n#### 三、nginx-https模块配置\n\n- **1. 反向代理基础配置（http模块）**\n\n依照前文基础配置的`nginx.conf`模板进行修改即可。\n\n- **2. ssl证书申请及https模块配置**\n\n遵循`复制模板`-`注释`-`解除注释`-`申请`-`解除注释`的“五步原则”。注释及解除注释操作的对应模块如下：\n\n**注释**：注释**http反向代理模块**  \n**第一次解除注释**：解除**http ACME验证挑战模块**注释  \n**第二次解除注释**：解除**https反向代理模块**注释\n\n--- \n完成以上三大步，8小步的配置与部署操作，部署工作基本也就完成了。\n\n## 常见问题\n\n部署过程中经常会碰到一些奇奇怪怪的问题，特别是不熟悉docker、nginx配置规则的初学者。下面是我在部署过程中遇到的问题的汇总。\n\n### nginx错误、服务访问错误\n\n通常表现为nginx容器无法正常运行，网页访问`500`、网页访问`502`等，具体原因可能有如下几种：\n\n- `nginx.conf`配置错误\n\n通常是反向代理模块中`proxy_pass`参数的配置有误，比如后端服务的**端口**或**服务名称**与`docker-compose.yml`中配置的不对应。\n\n- `docker-compose.yml`配置错误\n\n通常是前文提到的不同容器间关系的配置有误或者缺失，特别是nginx服务与其他需要通过nginx服务进行转发的服务之间的关系。如`networks`配置、容器依赖关系配置；以及前文提到的服务配置与docker-compose配置的对应关系问题，如服务端口的对应问题。\n\n### ssl证书申请（certbot）错误\n\n通常表现为无法申请ssl证书、申请证书后访问显示“~~https~~网页不安全”等，具体原因可能有如下几种：\n\n- 无法申请ssl证书（certbot无法正常运行）\n\n**1. 同一域名在短时间内申请次数过多**\n\n**2. `nginx.conf`中http ACME验证挑战模块配置有误**\n\n**3. 在特殊环境（如需要进行用户验证）下未注释http反向代理模块导致无法访问服务的问题（如`401`）**\n\n**4. 域名本身无法正常访问（`5xx`、`4xx`）**\n\n- 访问问题（提示网站不安全）\n\n**1. 申请ssl证书时信息有误，如二级域名名称错误**\n\n**2. `nginx.conf`中https模块二级域名（server_name）配置有误**\n\n**3. `nginx.conf`中https模块证书路径有误**\n\n关键在与证书与域名的对应关系是否有误。\n\n---\n**END**\n\n","tags":["web开发","docker"],"categories":["projects"]},{"title":"Hello :)","url":"/2025/03/10/Hello/","content":"\nThis is the first content for my blog :) <br>\n\n![Hello](https://butterblock233.github.io/posts/images/Hello.gif) <br>\n\nGIF source: [Hello Apple by Meritt Thomas](https://dribbble.com/shots/17347386-Hello-Apple) <br>\n","categories":["test"]}]
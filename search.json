[{"title":"2024-2025：艰难的起步","url":"/2025/06/20/2024-2025summary/","content":"\n在大学的第一年——也是正式开始CS自学旅途的第一年（周年）随着暑假的临近也就快要结束了，是时候乘着 ~~期末复习~~ 休闲的时间写一下这个学年的学年总结与复盘了。\n\n事实上，对于这个学年的成果我个人并不满意，但也正因如此，才需要通过客观、辨证的总结来修正错误的方法与方向。\n\n## 做了什么\n\n似乎做了很多，又似乎什么都没做.....🙃至于为什么，后面再分析。\n\n\n### 暑假\n\n- 第一台个人计算机💻\n\n  拿到第一台个人💻（家里的电脑基本不让我动，而且其本身基本也成为**赛博养蛊**的载体了）的第一件事就是下 ~~steam~~ **vscode**，之前在高中的时候在班级的多媒体设备上不知道为什么“下不了”，好不容易下好了发现不会配环境😅；\n  \n  同时因为某些不明原因，班级里有些人似乎对我使用“公共设施”学习抱有意见——明明特地挑了不会影响他们的时间与方式，而且我个人也是管这个的班干部，也不知道是不是觉得我在装X.....~~现在想想，当时的脸皮还是太薄了~~\n\n  不小心说了点废话，总的来说，我在拿到这台电脑前几乎是没有任何渠道可以自学CS的，因此当时的心情是十分激动的，这台电脑几乎就是我最初的学习CS的工具。至于“为什么不看书”、“不会手写代码吗”这类言辞相信应该不会从能看到这篇文章的人嘴里说出；而且我真的去看了，举一个最典型的例子：我永远也不会忘记当时作为一个毫无CS基础的白痴，翻开[这本书](https://csappbook.blogspot.com/)后我的反应😅。\n\n- 自学了C语言的基础\n\n  这几乎占据了我暑假里60%的个人时间，所以我暑假期间直到8月底快要入学了都没有离开我从小生活的县城。\n\n  虽然但是，我是**花钱**看的网上所谓的培训班学的，这里就不展开了。\n\n- 在一位福大信息安全的朋友的帮助下初步了解了科学上网🪜的方法\n\n  这个虽然不起眼，但是十分重要，可以说是改变我获取资源的途径的基础，只不过当时没意识到\n\n### 上学期\n\n这是在大学的第一个学期，主要以信息收集为主，同时兼顾学业以争取转专业名额。\n\n- 了解在大学中计算机“破局”主要的三个方向：**项目**、**竞赛**、**科研**\n\n- 结识了许多校内计算机方向的大佬与老师，主要是技术/安全协会的学长学姐与安全方向的同届同学\n\n- 在大佬与老师的引导与帮助下彻底放弃了“跟班”式的学习方式\n\n  说起来也有点意思，暑假报的那个培训班我在入学后不久就退款了，原因有二：一是与我当时感兴趣的方向（安全）不太一致；二是我发现里面所谓的指导老师似乎对于计算机行业的认知还不如我，负责技术指导的老师更是 ~~人机~~ 连工具都不会用。举个最难绷的例子，我用vscode（众所周知，vscode本身是文本编辑器而不是IED）时碰到了一个最简单的配置问题，甚至都不需要修改配置文件，他上来就让我把编辑器换成他们教学指定的IDE，而我在搜索了资料后发现就是环境变量的问题.....更搞笑的是我是在他们课程的宣传广告或着叫**公开课**上的某个视频还是评论找到解决方案的🤣。不过好在人家最起码不是诈骗，退款还是可以退的，但还是赔了亿点点（因为看了一点课）。\n\n  后面我在参与学校与某个企业联合举办的竞赛时又双叒叕被推送了他们自己的培训方案，这一次我是差点就交了近3万的培训费去学所谓的“网络工程”，当初对网络安全很感兴趣，头脑发热就去问了，好在最后被某个大佬和老师拦下了。这次也不是没有收获，除了彻底抛弃了“跟班”思维，决定自己独立定制我个人的**培养方案**，也认识了 `Cyber Security` 与 `Network Security`的区别（虽然不敢讲全部，但他在所谓的竞赛培训上讲的内容，除了**思科模拟器**的使用，其他内容我基本有一定的了解）\n\n  总而言之，从这里开始，我的**CS自学之路**或许才真正意义上称得上是**入门与起步**。乐观的讲，至少没有中道崩殂吧.....🙃\n\n- 与网安同届的同学组队打了几次CTF线上赛\n\n  虽然都是一些小比赛，外加压根就没什么水平，所以挺水的，不过也结识了网安的朋友，同时由于我们学校对这方面不太重视，CTF鲜为人知（甚至连前面提到的安全协会都是基本只有网安专业的同学知道），为后续转专业提升了个人竞争力。\n\n  社会工程学魅力时刻了属于是😁\n\n- **翻出了在网页收藏夹中积灰已久的[csdiy](https://csdiy.wiki/)**\n\n  在整理网站资源的时候发现了早在高中时朋友就推荐的[CS自学指南](https://csdiy.wiki/)，当时因为**没有科学上网工具**打不开，但多少知道这是个宝藏，然而这时已经临近上学期期末了（你猜我前面为什么说我没意识到*科学上网是改变我获取资源的途径的基础*），也就是说我“浪费”了近一个学期的时间走了CS自学的“第一条弯路”，是的，这只是第一条🙃。\n  \n  还有一点忘了说，在再次发掘出这个宝藏前放弃“跟班”式学习后，我的自学几乎依靠形如[菜鸟教程](https://www.runoob.com/)的**文档式教程**。至于我对文档式教程的看法，我个人认为其更适合用于**快速参考**或某些技术栈的**入门速通**，不建议在深入学习时依赖——**文档之所以被称之文档就是因为其“仅供参考”**\n\n- 使用积蓄购买了第二台💻\n\n  这是一个艰难但在我看来正确的一个决定。冒着被扣上“乱花钱”帽子的风险，主要还是为了一劳永逸地解决我一直以来头痛的续航问题，但出乎意料的，这台轻薄本（我给其编号为`PC1`，第一台自然就是`PC0`）对于生产环境的兼容性似乎远超`PC0`，这解决了另一个使我头痛的问题——`PC0`上一些困扰了我很久的兼容性问题；日常的使用体验也是如此，也不知道是不是因为`PC0`是我的第一台个人电脑，我没正确维护导致的兼容性问题。\n\n### 寒假\n\n- 速通[MIT Missing Semester](https://csdiy.wiki/%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/MIT-Missing-Semester/)\n\n  对于里面大部分内容的**基础操作**在上学期的“弯路”中多少有点了解，如Git、Shell等。可惜的是我并没有静下心来完善进阶部分，这个问题实际贯穿了整个学年的学习，后面会做分析。\n\n- 开始使用Linux操作系统\n\n  这也可以算得上是一个重要的节点。起因是我在学习[MIT Missing Semester](https://csdiy.wiki/%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/MIT-Missing-Semester/)时，本意是使用VM来学习Shell，然后就碰到了该死的 “没有正确卸载VM” 导致的一系列问题（历史遗留问题.jpg）。在给`PC0`几次重置重装系统无果后，一怒之下，我就看着网上的教程和资料给`PC1`装了双系统（Ubuntu22.04 + Win11） \n\n- 自学[CS61A](https://csdiy.wiki/%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/Python/CS61A/)\n\n  这可以称得上是“斯大林格勒”了（好吧其实没那么夸张），看这门课时我和[csdiy第一贡献者的感想](https://csdiy.wiki/#cs61a)是一致的。\n\n### 下学期\n\n- 创建了自己的第一个独立项目——基于[CS61A](https://csdiy.wiki/%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/3Python/CS61A/)的学习用py手搓了一个简陋的[立体几何计算器](https://github.com/virtualguard101/space-calculator)（简陋到甚至都不支持曲线与曲面）\n\n- 在导师的邀请下开始试图参考网上[大佬的项目](https://zhuanlan.zhihu.com/p/714400366?utm_psn=1883987006549374851)使用FPGA来[“手搓GPU”](https://projects.virtualguard101.xyz/posts/gpu-researching-log/)\n\n  可惜我对硬件方面确实没有太大的兴趣，加上缺少这方面的基础与我对自身学习进度的认知偏差，导致我在一些不必要的地方“浪费”了很多时间。因此这个项目在现阶段而言对我的帮助我个人认为十分有限。\n\n#### 5月份\n\n- 构建了自己的[个人站点](https://virtualguard101.xyz/)\n\n  ![](https://i.imgur.com/euiV0r7.jpeg)\n\n  在正式踏上自学之路后不久，我一直在探索能够高效整合信息/资源（人话：记笔记）的方式，特别是在五月份受导师邀请开始“手搓GPU”后，单位时间里需要接收的信息量越来越多，脑子里能留住的有效信息却越来越少。最后思来想去还是发现**使用`CI/CD`构建的个人站点**最合适。\n\n  这里要特别感谢学校技术协会的大佬，对站点建设提供了一系列相对现代化的构建建议。\n\n  建站后在协调大量信息的存储与分类时我也遇到了不少麻烦，包括但不限于如何选取合适的主题/文档构建工具来使博客更加美观且实用、哪些构建工具/框架适合用于笔记以使其能够被高效地回顾、查阅等，这些我们[后面](#经验总结)再谈\n\n- 自学[CS106L](https://csdiy.wiki/%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/cpp/CS106L/)\n\n  这是建设了个人站点后的第一个具有[相对完善笔记](https://note.virtualguard101.xyz/notes/Programming%20Language/c%2B%2B/C%2B%2B%20Fundamental/00-type-structure/)的自学课程，我快速过了一下，其中大部分的[Assignments](https://github.com/virtualguard101/cs106l-assignments)还没来得及做。\n\n- 开始使用Arch Linux作为主操作系统\n\n  ~~因为我是男娘~~\n\n  使用了近半年的Ubuntu，终于还是对Arch动心了。[这篇文章](https://blog.virtualguard101.xyz/2025/05/19/arch-linux/)记录了一些我在安装过程遇到的一些要点与问题。\n\n- 创建项目[3BodySimulator](https://github.com/virtualguard101/3BodySimulator)\n\n  这是我个人为学习C++项目构建与管理而创建的**案例式项目**，学习的知识主要聚焦于cpp项目的构建流程与[CMake等工具的使用](https://note.virtualguard101.xyz/notes/tools/Build%20Tools/cmake/)，代码逻辑的所有内容以及项目架构的部分内容由AI代为完成。\n\n  按照惯例（自从有个人站点后，我有随手为自己的项目写文档的习惯，特别是用于学习的项目），我也为此写了一篇[解构文档](https://blog.virtualguard101.xyz/2025/05/23/3BodySimulator/)\n\n- 转专业拟接收名单公示，不出意外的话就是成功转入网络空间安全了\n\n  转入网安主要还是因为我们学校这个专业后期课程量相对较少，算是为未来的自己争取到了一点时间吧\n\n#### 6月份\n\n- 进一步完善了[Git的学习](https://note.virtualguard101.xyz/notes/tools/git/)\n\n  说的难听一点，对于Git在此之前我可能只会“三板斧（`add`、`commit`、`push`）”\n\n- 基本明确自己的努力方向——围绕自动化与云原生，目标岗位基本明确为后端开发、服务器开发、自动化类岗位（构建开发、测试开发等）三者或类似岗位\n\n  这也是一个看起来并不起眼但却十分重要的一个节点，它标志着我一年以来“内耗式”学习的终结，其中问题与经验我们后面再谈\n\n\n## 问题所在\n\n### 学习方面\n\n是时候进入最为重要的**问题总结**与**纠错**环节了，错误本身并不可怕——可怕的是缺乏面对错误的勇气\n\n\n#### 一系列“左倾”错误导致的连锁反应\n\n>这是一个**系列问题**\n\n由于是系列问题导致的连锁反应，以一种**自顶向下**的方式来分析问题就会稍微方便且清晰。下面的流程图将问题之间以及问题与其导致的后果以**图**的形式从实际问题中**抽象**出来，以便后续的分析与解决（本来想用[mermaid](https://mermaid.js.org/intro/)的，但写了半天发现渲染不出来，最后用的文档扫描转图片）：\n\n![](https://i.imgur.com/xbuGDDR.jpeg)\n\n\n图中的分析虽然不尽完美，但已经把一年以来最为主要与急需解决的以一种抽象的方式问题总结出来了（毕竟这是我第一次采用这种分析法分析问题）\n\n外因的情况较为特殊，同时其对自学的影响已经不再是实质上的影响了，这里简要说明\n\n- 外因（环境因素）\n\n  在暑假和上学期，我的**独立自主**学习意识十分薄弱。这里的“独立自主”不单指**学习积极性**，还包括**信息收集能力**、**自主规划能力**、**信息整合分析能力**。如果单单只有满腔热血，在当今互联网信息良莠不齐的时代这一点反倒更有可能成为自学时致命的缺点，在网络广告的诱导下差点陷入“跟班”式学习（那就不叫自学了）的陷阱就是一个再好不过的例子。然而这种能力似乎真的看个人——或者说需要时间沉淀；同时，国内的计算机教育与网络环境懂的都懂，下面两张截图的对比（前后分别是同一搜索对象，**未使用科学上网工具、国内版edge的搜索结果**与**开启了科学上网工具、chrome的搜索结果**）就是一个例子：\n\n  ![未使用科学上网工具、国内版edge的搜索结果](https://i.imgur.com/EMEvQ2c.jpeg)\n\n  ![开启了科学上网工具、chrome的搜索结果](https://i.imgur.com/m4yxp37.jpeg)\n\n  或许是因为在高考结束前压根就没有自学计算机的环境，导致我刚开始时一直在**试错**与**走弯路**；虽说在高考前我在朋友的帮助下对计算机的行业信息与国内的本科教育现状（特别是计算机方向）已经有了初步的了解，但说实话，真的只是**冰山一角**，一方面缺少**科学上网**工具，另一方面没有那种明确目标的意识，二者在CS的学习中都是十分致命的问题，特别是自学。\n\n  将问题归结到环境上并不是推卸责任，计算机这个行业本身就是一种经验性且重环境的的东西，没有日积月累的沉淀与深耕是不可能有真正意义上技术成果的（实际上大部分领域都是这个道理，但是计算机领域介于其资源获取方式的特殊性，相较其他领域或许两极分化更加明显），这是基于我一年以来对身边技术朋友的观察得出的结论。\n\n针对外因，只要学习积极性不变且有一台（可联网的）计算机可以操作，其影响会随着经验的积累而逐渐减弱——自高考结束后，“中式教育”的高压约束不复存在——相反，这时我的父母反而会十分支持我，哪怕我没有成为他们希望的模样。已经流逝的时间无法挽回，与成为真正大佬的差距现在只能靠在日常多花数倍的时间沉淀来弥补\n\n简单来说，**高考结束后，外因也就转化为内因了**，即条件/环境与学习需求的矛盾转化为了自身学习能力与期望效率之间的矛盾，但前提是校内学业压力的可控，否则学业问题会消耗很多时间。\n\n\n事实上，这幅图主要还是聚焦于“内因”的分析，同时还有一个类似**递归**的节点关系——这点我没有处理好，导致其有点难以理解：\n\n注意图中有一个名为“内因”的节点`G`，与我们所言的内因实际上是一个东西，可以简单将其视为**除外因（`F`）节点外，图中其他所有节点的封装**——它的位置与关系或许不恰当，但它想要说明的问题是：**内因综合在一起本身就会与使得学习/信息整合能力低下，而由于学习积极性高涨，学习需求强烈，后者又会加剧前者“内耗式学习”与“急于求成”的问题，从而陷入一个巨大的恶性循环**。\n\n\n现在注意力来到这幅图抽象出的“最本质”的问题，即分属于两个核心问题的四大矛盾：\n\n  - 学习规划上具体方向不明确\n\n    - 学习需求与个人认知之间的矛盾（因果）\n\n    - 信息过载与有效筛选之间的矛盾（因果）\n\n  - 学习进程上急于求成\n\n    - 个人实际能力与期望能力之间的矛盾（因果）\n\n    - 学习行为与学习规律之间的矛盾（原理）\n\n现在就不难发现，所谓的“左倾”，指的是**在学习进程上急于求成**，而忽略了个人的实际能力；另外，缺少高效的信息整合方法也是这一年以来学习方法问题上巨大的痛点，但这也需要在漫长的学习过程中总结转化，与“急于求成”的学习作为也是矛盾的。\n\n至于学习规划上的问题，两个矛盾甚至是问题本身的指向就已经十分明确了，一是缺乏认知，二是未能合理筛选信息——这就回到刚刚说的个人能力的问题了，也需要时间进行学习转化。\n\n值得庆幸的是，经过一年以来的摸爬滚打，对于学习规划上的问题，我已经积累了足够的经验，以至于我在写这篇复盘前的一周便彻底明确了自己的努力方向，这在[做了什么](#6月份)中也有所提及。\n\n至于“急于求成”的问题，抛弃不切实际的幻想，脚踏实地走好每一步就是最好的解决方式。\n\n#### 时间实际利用率低\n\n这个问题除了上面所说的“效率问题”，还有一部分是作息安排上的问题\n\n作息不规律导致的时间浪费也是一年以来学习规划上的痛点，同时我的身体健康也因此受到了不小的影响\n\n#### 学习过程中难以静心\n\n这个问题除了上面图中所说的“急于求成”以外，还有一个原因就是我玩心本来就挺重的（这个懂的都懂😋），对于自己感兴趣的领域，我总是喜欢“超前”地了解些新东西。\n\n对于这个问题，辨证地看待它不难发现，它在我刚开始自学的那段时间客观上促进了我摆脱“跟班式”学习的陷阱；然而随着学习进程的推进与日益增长的信息量，这个问题对我的影响开始由利转弊了——它开始成为我高效学习与整合信息的障碍（[黄金替罪羊.jpg](https://www.bilibili.com/video/BV1sFLMzJEgU/)）。有意思的是，这个问题在我高考前的应试教育学习阶段也是一个十分突出的问题，只不过当年的我还是太年轻，没有及时系统分析自己在学习上存在的问题。\n\n对于现阶段如何解决这个阻碍，除了下文提到的[学与玩的边界](#未能清晰划分学与玩的界限)外，还可以专门腾出一部分时间“顺其自然”，把它当作是一种“预习”——将这个行为利用起来，而不是尝试去克制、抹杀它。对于源于本性的问题，想要在短期内快速解决，“大禹治水”式的方式是最合适的。但仍需注意时间安排的问题，或是说是一种“划分”问题——这就与[下文](#未能清晰划分学与玩的界限)联系起来了。\n\n### 实践方面\n\n#### “闭门造车”\n\n主要问题是在开发实践中脱离实际，过度“独立”，团队协作意识薄弱，团队协作开发技能（如Git分支相关操作、代码审计等）能力低下\n\n#### 未能清晰划分“学”与“玩”的界限\n\n这个虽然是前面分析[一系列“左倾”错误](#一系列左倾错误导致的连锁反应)时那副关系图中提到的一个节点问题，但我认为有必要就学习规划的角度将其拿出来讲一讲。\n\n“玩”与“学”的关系其实是很微妙的：在技术领域（其他领域我不知道），二者可以相得益彰，但也可以“相克相制”，取决于学习的方法。倘若**玩的东西的实际意义不大**或是**与“学”的关联性较低**，那么这种“玩”就与学无益——最多提供些情绪价值。\n\n对于我过去一年以来的经历，前者的占比似乎不大，这是效率上的问题；而后者就有“好高骛远”的嫌疑，这也和前面的分析一致。\n\n解决方法有两个：一是在学某个模块的内容时专注于“玩”这个模块的内容；二是彻底分割二者的关系。两种方法各有利弊，前者专注而略显枯燥、后者灵活而略显低效。对于后者，还有一个“改良版”——结合两者的特征，同时存在两个“玩”的内容。因为仍需划分“学”与“玩”，故本质上还是后者，且对规划能力与自制力的要求高。\n\n## 经验总结\n\n其实前文都总结得差不多了，不过这里还有两个经验需要补充：\n\n- 一个在[明确自己努力方向](#6月份)时的发现：\n\n  在分析部分互联网大厂的JD时，我发现校招的任职要求更多指向**计算机基础知识**，而社招才更加注重**工程或业务能力**。那么我们不妨大胆推测——对于像我这样高考结束后才开始接触技术而缺乏技术沉淀的人，扎实的计算机基础或许才是更加稳妥的大厂敲门砖。\n\n- 还有一个经验是在通过搭建个人站点来整合信息时得出的——**站点构建工具与主题的选择**：\n\n  这对于我这样的初学者也是一个容易走弯路的地方，我在这个地方至少“浪费”了近一个月的时间。\n\n  长话短说，首先来看一些工具——我目前调研过的构建工具有四个：[Hugo](https://hugo.opendocs.io/)、[Hexo](https://hexo.io/zh-cn/)、[Material for MkDocs](https://squidfunk.github.io/mkdocs-material/)和[VuePress](https://vuepress.vuejs.org/zh/)，其中前面三个我都用过，第四个简单看了一下。\n\n  我个人的建议是，针对**博客**等**非信息密集型**且**注重美观**的文档或站点，可以使用前两个构建；同时，Hexo会比Hugo更加成熟一些，大部分第三方主题对前者的支持会更好，但是容易出现依赖问题，且可能需要手动解决。因此建议小白用Hugo，有一定经验了再迁移到Hexo。\n\n  而对于类似**学习笔记**这样**结构复杂**的**信息密集型**文档，建议使用Material for Mkdocs。其社区支持十分完善，且支持[PyPI集成](https://pypi.org/project/mkdocs-material/)，可通过自行编写Python插件自定义样式。[csdiy](https://csdiy.wiki/)就是使用其构建的一个站点。\n\n  VuePress我倒是没使用过，不过通过观察使用其构建的文档，我个人认为它适合用于构建结构相对没那么复杂的**单主题**的**信息密集型**文档，如某个中大型项目的使用文档。\n\n\n## 新的开始\n\n新的学年，不出意外的话，我就是网安专业的学生了。~~芜湖～水课水课逃逃逃！😋~~\n\n在大二，计算机的基础学习与竞赛或许会成为我的主旋律。在《葬送的芙莉莲》中，一级魔法使[兰托](https://zh.moegirl.org.cn/%E5%85%B0%E6%89%98)在一级魔法使选拔考试上曾对自己的对手说过这样一句话：**大部分自学成才的人基础都不够扎实**——希望能够成为剩下的那小部分人。\n\n对于基础学习，重点放在**操作系统**与**计算机网络**上，最好能手搓一个内核和TCP/IP协议栈。我总有一种感觉，就是我目前的实际开发能力极其低下的一个能重要的原因就是对操作系统的原理几乎完全不了解。\n\n最好能把“程序员的三大浪漫”（操作系统、编译原理、计算机图形学）也过一遍。\n\n当然，工程/业务能力也要尽可能不落下，特别是这学期分外重视的**项目标准化**。\n\n---\n*END*\n\n<div style=\"text-align: right;\">\n  -- virtualguard101，2025.6.23凌晨于福建理工大学\n</div>\n","tags":["学年总结"],"categories":["Misc"]},{"title":"3BodySimulator：Python & C++ 项目标准化构建","url":"/2025/05/23/3BodySimulator/","content":"\n## 导言\n近期刚刚结束[CS106L | Standard C++ features and syntax](https://web.stanford.edu/class/cs106l/)的学习，想借此机会完善一下对C++项目构建的学习，如`CMake`等构建工具的使用，故立此项。\n\n通过本次项目你会了解到：\n\n- 1. C++项目标准化基础\n\n- 2. `CMake`、`vcpkg`等C++构建工具的基本使用\n\n- 3. 多语言配合构建（C++ & Python）\n\n下面是完成此次项目所需的基本条件：\n\n- C++ 编译器\n\n- [Git](https://git-scm.com/)：版本控制\n\n- [CMake(*>= v3.22*)](https://cmake.org/documentation/)：C++构建工具\n\n- [vcpkg](https://learn.microsoft.com/zh-cn/vcpkg/)：C++包管理工具\n\n- [Python(*>= v3.12*)](https://www.python.org/)：可视化模块\n\n- [uv](https://docs.astral.sh/uv/)：Python包管理工具\n\n文中的构建平台为**Ubuntu22.04**\n\n此次项目注重C++项目的标准化以及构建工具（`vcpkg`、`CMake`）的使用，代码逻辑部分主体由`DeepSeek`、`ChatGPT`等AI大模型完成。\n\n- 项目仓库：[3BodySimulator](https://github.com/virtualguard101/3BodySimulator)\n\n## 初始化项目\n\n首先使用两个语言的包管理器分别对项目进行初始化：\n\n### `vcpkg`\n\n```bash\nvcpkg new --application\n```\n\n对生成的`vcpkg.json`进行配置：\n\n```json\n{\n    \"name\": \"three-body-simulator\",\n    \"version-string\": \"0.1.0\",\n    \"dependencies\": [\n        {\n            \"name\": \"python3\",\n            \"version>=\": \"3.12.9\"\n        },\n        \"pybind11\"\n    ],\n    \"builtin-baseline\": \"a337f5fe100f83026072765ea63a8776f984f6fd\"\n}\n```\n\n>注意所有键值对的内容只能包含**小写字母**，否则后续构建时会报错。\n\n### `uv`\n\n```bash\nuv init\n```\n\n将项目信息写入`pyproject.toml`\n```js\n[project]\nname = \"3BodySimulator\"\nversion = \"0.1.0\"\ndescription = \"The visualization simulation of three-body motion implemented using C++ & Python.\"\nreadme = \"README.md\"\nrequires-python = \">=3.12\"\ndependencies = [\n    \"matplotlib>=3.8.0\",\n    \"ninja>=1.11.1\",\n    \"numpy>=1.26.0\",\n    \"pybind11>=2.11.1\",\n    \"pygame>=2.6.1\",\n]\n```\n\n随后去除无用的生成配置即可。\n\n随后对项目结构初始化：\n\n### 项目结构\n```bash\n.\n├── build.sh              # build shell script\n├── CMakeLists.txt        # CMake build config(outer)\n├── CMakePresets.json     # vcpkg CMake toolchain config(public)\n├── CMakeUserPresets.json # vcpkg CMake toolchain config(private)\n├── LICENSE\n├── pyproject.toml        # Python project config\n├── python                # Python script folder\n│   ├── dynamic.py\n│   ├── example.json      # example input json data\n│   ├── pyonly.py\n│   └── visualize.py\n├── README.md\n├── requirements.txt      # Python dependencies\n├── src                   # C++ source folder\n│   ├── CMakeLists.txt    # CMake build config(inner)\n│   ├── three_body.cpp\n│   └── three_body.h\n├── uv.lock\n├── vcpkg-configuration.json\n└── vcpkg.json            # vcpkg dependencies config\n```\n\n## 代码实现\n\n这部分并不是我们本次项目的重点，故使用了大语言模型（[chatGPT](https://chatgpt.com/)）负责该部分的实现与完善。~~绝对不是我想偷懒😋~~\n\n其中采用的技术栈在项目的[README](https://github.com/virtualguard101/3BodySimulator?tab=readme-ov-file#tech-stack-in-this-project)中有详细的总结。后续会视情况完善对这一部分的学习和解构。\n\n在实现的代码源文件中，我们使用C++作为**底层物理引擎**的构建语言，使用Python作为**主程序语言**并负责**可视化与用户交互**。二者的源文件分别位于项目根目录的`src`和`python`文件夹下。\n\n## 项目构建\n\n接下来进入本项目的重点。\n\n创建本次项目的主要目的是为学习**CMake**和**vcpkg**的基本使用，故将项目构建配置的部分视为重点。\n\n本项目使用`CMake` & `vcpkg`工具链进行C++的构建，使用`uv`进行Python的依赖与项目管理，可遵循『**获取依赖→配置→编译→虚拟环境运行**』的流程对项目进行构建与测试运行：\n\n### 获取依赖\n\n类似Python的`pip`，`vcpkg`是一个相对简单易用的cpp包管理工具（虽然但是各种配置还是让人用的很难受🙃，毕竟C++的生态就这样），在该项目中，我们将使用它相对容易地获取项目所需的相关依赖。\n\n安装就不再赘述，详情参考[官方文档](https://learn.microsoft.com/zh-cn/vcpkg/)，注意记住自己安装的路径，以便后续工具链的配置。\n\n- 编辑依赖列表\n\n在本项目中，我们选择使用C++配合Python完成模拟实现。chatGPT给出的实现思路是**使用cpp实现天体运动的底层物理引擎，构建输出一个Python可直接调用的共享库（`.so`/`.pyd`），然后由Python在可视化实现中直接调用**。\n\n因此，在C++模块的实现中，我们需要使用[pybind11](https://pybind11.readthedocs.io/en/stable/basics.html)联系二者。\n\n>`pybind11`是一个轻量级的库，用于将C++代码绑定到Python中，使得Python能够调用cpp的高性能代码。\n\n为了引入`pybind11`，我们就需要通过配置`vcpkg.json`的依赖列表使得后续运行构建时能够导入它。\n\n在**初始化项目**的过程中，我们已经对`vcpkg.json`进行了配置。是的，那就是所谓的**依赖列表**。根据[官方文档](https://learn.microsoft.com/zh-cn/vcpkg/get_started/get-started?pivots=shell-bash#3---add-dependencies-and-project-files)的描述，也可通过`port`命令添加依赖：\n```bash\nvcpkg add port pybind11\n```\n\n### 构建配置\n\n这是该项目中最为重要的一步，主要的工作简单来说就是配置`CMakeLists.txt`。\n\n由于我们使用了第三方工具`vcpkg`作为包管理工具，合理配置这二者之间的工具链关系就尤为关键。\n\n我们配置的思路是，在项目的根目录和用于存放C++模块的`src`中分别创建一个`CMakeLists.txt`。前者用于配置CMake在构建过程中与vcpkg的工具链参数；后者则专门用于配置cpp模块的构建逻辑。\n\n由此便有了以下配置：\n\n`CMakeLists.txt`:\n```bash\n# 项目基本参数\ncmake_minimum_required(VERSION 3.20)\nproject(3BodySimulator LANGUAGES CXX)\n\n# 使用 vcpkg 的 Toolchain\nif(NOT DEFINED CMAKE_TOOLCHAIN_FILE)\n  set(\n    CMAKE_TOOLCHAIN_FILE \"~/vcpkg/scripts/buildsystems/vcpkg.cmake\"\n    DPython3_EXECUTABLE=$(which python)\n    DCMAKE_BUILD_TYPE=Release\n    CACHE STRING \"\"\n  )\nendif()\n\n# 把 src 子目录加入构建\nadd_subdirectory(src)\n```\n\n`src/CMakeLists.txt`:\n```bash\n# 查找 pybind11（由 vcpkg 安装并集成）\nfind_package(pybind11 CONFIG REQUIRED)\n\n# 源文件列表\npybind11_add_module(three_body\n  three_body.cpp\n)\n\n# 设置头文件路径\ntarget_include_directories(three_body\n  PRIVATE ${CMAKE_CURRENT_SOURCE_DIR}\n)\n\n# 设置 C++17 标准\ntarget_compile_features(three_body PUBLIC cxx_std_17)\n\n# 把生成的共享库 (.so/.pyd) 放到 ../python 目录\nset_target_properties(three_body PROPERTIES\n  LIBRARY_OUTPUT_DIRECTORY ${CMAKE_SOURCE_DIR}/python\n  OUTPUT_NAME \"three_body\"    # 忽略 ABI tag，统一输出 three_body.so\n  PREFIX \"\"                   # 无前缀\n  SUFFIX \".so\"                # 强制后缀 .so\n)\n```\n\n正常情况下，按照以上构建配置，只需执行如下命令即可进行C++模块的构建生成与编译：\n```bash\n# 配置生成\ncmake --preset=vcpkg\n# 编译生成.so\ncmake --build build/\n```\n\n如果不出意外的话，cmake会在`python`路径下生成一个名为`three_body`的`.so`共享库（为了方便调用，故将共享库生成到与py脚本相同的目录下）。事实上，到这里，我们的项目就可以直接通过`python`命令直接运行了（当然，前提是你的Python依赖没有问题）。\n\n~~uv：世界，遗忘我...🙃~~\n\n### `uv`Python虚拟环境配置\n\n虽然完成了C++模块的构建工作基本就意味着项目能够跑起来了，但Python混乱的环境依赖问题在某些时候是出了名的让人头痛。为了避免这一情况，我们需要创建一个虚拟环境来运行我们的项目，为此，我们选择了[uv](https://docs.astral.sh/uv/)作为该项目的Python包管理器。\n\n>`uv`是一个由`Rust`编写的高性能Python包管理工具，其安装速度比传统工具要快上不少，同时还支持并行安装。\n>\n>更重要的是，它提供了一种十分便捷和强大的**项目依赖管理**与**虚拟环境管理**方式。\n\n在初始化项目的过程中，我们已经使用其进行了项目信息的初始化配置，接下来，我们将继续使用它轻松地配置和运行我们的项目：\n\n- 创建Python虚拟环境并激活\n```bash\nuv venv .venv         # 默认为系统 Python3.12\nsource .venv/bin/activate\n```\n\n- 在虚拟环境中安装依赖\n```bash\nuv pip install -r requirements.txt\n```\n\n安装好依赖后，我们就可以在虚拟环境中完美地运行我们的项目了：\n```bash\nuv run python/dynaminc.py\n```\n\n### 自动化构建脚本\n\n说了这么一堆，有人可能要问了：这么多的构建命令，还挺麻烦的，而且如果不小心搞乱了不就完犊子了？难道就没有方便的构建方式吗？\n\n有的兄弟，有的。\n\n事实上，我们上面讲解的构建顺序本身就有点问题：\n\n如果观察仔细的话，应该会注意到，前文中根目录下的`CMakeLists.txt`中在配置工具链时指定了一个名为`DPython3_EXECUTABLE`的参数，这个参数的功能是显式指定运行Python脚本的Python解释器，作用是强制保持运行环境的Python版本一致性。如果你在系统上使用与`uv`配置中Python版本不一致的解释器，且没有在构建C++模块前创建并激活Python虚拟环境，那么你在尝试运行项目时就会得到类似下面的报错信息：\n```bash\nTraceback (most recent call last):\n  File \"/home/virtualguard/projects/researching/cpp-engine/3BodySimulator/python/visualize.py\", line 11, in <module>\n    from three_body import Body, step\nImportError: Python version mismatch: module was compiled for Python 3.10, but the interpreter version is incompatible: 3.12.9 (main, Feb 12 2025, 14:50:50) [Clang 19.1.6 ].\n```\n\n对于这个问题，我们就需要通过强制规范构建顺序来保证项目自始至终是在我们创建的虚拟环境中构建并运行的，以确保项目环境的一致性；结合前面提到的“方便地构建方法”，我们就可以将众多的构建命令依序整合到一个`bash`脚本中，也就是所谓的**自动化构建脚本**：\n\n`build.sh`:\n```bash\n#!/bin/bash\nset -e\n\n#———————————————\n# 1. 清理旧构建\n#———————————————\necho \"清理旧构建文件...\"\nrm -rf build python/three_body* .venv/ vcpkg_installed/ vcpkg/\n\n#———————————————\n# 2. 创建并激活 uv 虚拟环境（Python 3.12）\n#———————————————\necho \"创建并激活 Python 3.12 虚拟环境...\"\nuv venv .venv         # 默认为系统 Python3.12\nsource .venv/bin/activate\n\n# 安装 Python 可视化脚本依赖\nuv pip install -r requirements.txt\n\n#———————————————\n# 3. 用 venv 中的 Python 配置 & 编译 C++ 扩展\n#———————————————\necho \"配置 CMake（指向 venv 中的 python）...\"\n# cmake -B build \\\n#   -DCMAKE_TOOLCHAIN_FILE=~/vcpkg/scripts/buildsystems/vcpkg.cmake \\\n#   -DPython3_EXECUTABLE=$(which python) \\\n#   -DCMAKE_BUILD_TYPE=Release\n\ncmake --preset=vcpkg\n\necho \"开始编译 C++ 扩展...\"\ncmake --build build\n\n#———————————————\n# 4. 检查生成结果\n#———————————————\necho \"生成的 Python 模块：\"\nls -l python/ | grep three_body\n\n#———————————————\n# 5. 运行可视化脚本\n#———————————————\necho \"执行 uv run python/visualize.py 启动三体模拟...\"\necho \"执行 uv run python/dynamic.py 启动动态模拟...\"\n```\n\n首先为脚本添加运行权限：\n```bash\nchmod +x build.sh\n```\n\n随后就可以直接通过脚本进行自动化构建了：\n```bash\n./build.sh\n```\n\n此时由于项目环境独立于系统全局的Python环境，构建运行均基于这个虚拟环境，确保了环境的一致性，也就不会出现像上面的环境冲突问题了。\n","tags":["C++","Python","vcpkg","CMake","Build Tools"],"categories":["Projects"]},{"title":"Arch Linux安装要点记录","url":"/2025/05/19/arch-linux/","content":"\nArch Linux是一个支持高度定制化的Linux发行版，其采用滚动更新的方式对系统进行更新，更新策略激进，适合愿意花时间在自己系统的计算机用户或喜欢折腾的计算机用户。\n\n这里需要特别说明一点，在安装之前，需要反思自己是否真的适合使用Arch！否则Arch的高度定制化与激进的更新策略将会使你陷入极大的麻烦！毕竟高度定制化的代价就是你需要为系统付出比其他稳定发行版多得多的时间去维护它。\n\n## 基本安装\n\n针对这部分内容，教程[Arch Guide | Nakano Miku](https://arch.icekylin.online/guide/)有详尽的阐述，包括从安装准备到系统美化的所有内容。\n\n这里记录几个我在真机安装过程中遇到的问题。\n\n### 格式化EFI分区前未备份原有系统启动引导（双系统）\n\n我在安装过程中由于急于求成，在为EFI分区扩容时未备份原有系统（这里是Win11）的启动引导程序就直接将其格式化了，结果安装完Arch的基本系统才发现Win11进不去了.....\n\n虽说安装前有备份Win11的系统映像，但为了一个EFI分区动用这个实属大材小用，因为基本数据的分区并没有任何问题。在这个问题上，我选择使用WinPE镜像系统对Win11的启动引导进行还原。只需准备一个装有WinPE镜像的U盘，启动进入WinPE，按照下图的提示，选择修`UEFI`引导进行修复即可：\n\n![](https://i.imgur.com/8fTXOCP.jpeg)\n\n### 输入法异常\n\n这在教程[Arch Guide | Nakano Miku](https://arch.icekylin.online/guide/)有提示，（如果是按照此教程进行的安装）执行命令`fcitx5-diagnose`进行问题诊断并按照输出提示修复即可。\n\n### 杂项\n\n关于桌面环境的选择，可以参考这篇文章：[Xorg, X11, Wayland? Linux Display Servers And Protocols Explained\n](https://linuxiac.com/xorg-x11-wayland-linux-display-servers-and-protocols-explained/)\n\n## 在可移动设备安装\n\n该部分可参考[将Arch Linux系统安装在可移动设备上的要点 | ToBeHonest's BLOG](https://b2og.com/archives/23)。\n\n第一次安装中，我就将Arch装在了一个256G、使用USB3.1的U盘上，同时由于使用[虚拟机](https://arch.icekylin.online/guide/rookie/pre-virt.html)运行安装镜像，所以并没有碰到什么大问题。\n\n---\n**[参考文献]：**\n\n- [在可移动设备上安装 Arch Linux | Arch Wiki](https://wiki.archlinuxcn.org/zh-sg/%E5%9C%A8%E5%8F%AF%E7%A7%BB%E5%8A%A8%E8%AE%BE%E5%A4%87%E4%B8%8A%E5%AE%89%E8%A3%85_Arch_Linux)\n\n- [将Arch Linux系统安装在可移动设备上的要点 | ToBeHonest's BLOG](https://b2og.com/archives/23)\n\n- [Arch Guide | Nakano Miku](https://arch.icekylin.online/guide/)\n\n- [ArchLinuxTutorial | Arch Linux Studio](https://archlinuxstudio.github.io/ArchLinuxTutorial/#/)\n","tags":["Linux"],"categories":["Misc"]},{"title":"docker-compose + nginx快速构建个人站点","url":"/2025/04/26/web-build/","content":"\n## 导言\n\n起因是我决定搭建一个个人站点用于模块化整合资源，在搜罗主页主题时因为部署简单相中了[remio-home | kasuie](https://github.com/kasuie/remio-home)，有多简单呢？简单到只需要进行一些及其简单的配置（cv大法可用）后，在服务器上输入一行`docker-compose up -d`即可。结合大佬的一些建议和我自己的一些~~偷懒~~自动化的想法，便有了下文。\n\n如题，本文主要讲解如何从零开始在一台云服务器上利用docker-compose + nginx快速构建一个个人站点。得益于强大的现代化工具链以及开源社区的支持，我们完成这个简易项目所需的计算机理论基础并不多，甚至可以说是几乎为零，只需要知道文档应该怎么读，如何正确打开开发中的“cv大法”来为自己的自动化工具链编写配置文件。当然，最好有一点web开发的基础，这样在遇到意料之外的问题时不至于束手无策。\n\n通过该项目你会了解到以下内容：\n\n- **1. 远程服务器的基础使用**  \n- **2. docker、docker-compose部署服务的基础操作**  \n- **3. web开发实现原理基础——静态资源部署**  \n- **4. hexo静态网页生成工具的使用**  \n- **5. Github Action配置自动化部署**  \n- **6. nginx基础配置（反向代理、二级域名）**  \n- **7. 在容器内使用certbot申请ssl证书，并通过定时任务自动化续签**\n\n下面是完成该项目所需的基础条件：\n\n- 一台服务器\n- 一个有效域名\n\n**服务器**可在云服务器运营商处租用。国内比较可靠的运营商有阿里云、腾讯云等。\n\n**域名**同样需要在运营商购买，也可通过特殊手段申请免费域名（不过免费申请的域名如有人出钱购买就会被回收）。获得域名后根据DNS云解析平台的文档进行解析配置即可。\n\n## 准备工作\n\n### 部署环境\n服务器的初始配置可参考这篇文章[远程服务器的基础使用](https://note.virtualguard101.xyz/notes/%E5%B7%A5%E5%85%B7/ssh/)，这里不再赘述。由于需要使用`docker`进行部署，我们需要先在服务器上安装一下docker。通过以下命令安装：\n\n```bash\ncurl -fsSL https://get.docker.com | bash -s docker\nsudo apt install docker-compose\n```\n\n将当前用户添加到docker用户组：\n\n```bash\nsudo groupadd docker # 若尚不存在 docker 组，则需先创建\nsudo usermod -aG docker $USER\n```\n\n由于是通过容器部署服务，环境处于“隔离”状态，`nginx`无需下载安装，可通过镜像运行于容器中。\n\n### 主页测试部署\n\n首先挑选一个能够使用docker部署的web主页，这里我们以[remio-home | kasuie](https://github.com/kasuie/remio-home)为例。根据文档进行配置与部署，部署完成后访问对应端口，观察配置是否生效。\n\n按照主题文档配置完`docker-compose.yml`后，将宿主机的端口改为80（http默认端口），`docker-compose down && docker-compose up -d` 或 `docker-compose restart` 重启服务，通过外网设备进行访问，正常情况下和本地访问结果无异。也可通过端口转发在本地主机进行测试访问，具体这里不展开。\n\n在通过外网设备进行访问时，若先前配置了DNS云解析，可通过域名进行访问。\n\n## 静态网页资源测试\n\n### hexo基础使用\n互联网中有着数不胜数的静态网页生成工具，这里我们使用[hexo](https://hexo.io/zh-cn/)。\n\n首先进入[主题选择页](https://hexo.io/themes/)选择几个心仪的主题，随后根据主题文档和官方文档构建静态站点目录和安装依赖。然后还是各个配置文件的修改与测试，这个过程相对枯燥且繁琐。\n\n需要注意的是，有些主题在后面的部署过程中可能会出现各种各样的兼容性问题，遇到无法暂时解决的，可以更换主题。\n\n配置完主题后，通过`hexo s`命令测试生成静态网页，通过浏览器访问`localhost:4000`生成网页，查看是否符合预期。确认无误后，即可进入部署阶段。\n\n## 部署\n\n### Github Page + 用户自定义域名\n\n有Github Page静态网页部署经验的同志对此应该不陌生，配合hexo的[一键部署](https://hexo.io/zh-cn/docs/one-command-deployment)使用起来方便到不能再方便了，详情这里不再展开。针对此部署方法，就算不想看官方文档，网络上也有数不胜数的教程。\n\n这种部署方法固然方便，但只能部署（.github.io）或绑定到一个域名下（custom domain），若想要通过多个二级域名来分隔部署web资源，或是将来可能需要部署其他无法通过Github Page来部署的服务（如用户登陆服务、数据库服务等），这样的方法就会极大地限制web服务的可扩展性。简单来说，是否选择该部署方法取决于部署需求，确认只有存放静态资源的需求则该方法操作便捷且功能绰绰有余。\n\n### docker-compose + nginx\n\n废话说了这么多，接下来正片开始。\n\n在现代 web 开发中，使用 Nginx 代理不同的子域名到相应的 web 项目是一个常见的需求。同时，为了使我们的web服务能够与使用docker容器部署的主页处于同一个服务端口上，我们就需要把处于不同容器的web服务通过docker-compose合成为一个，并映射到宿主机的80端口上以供外界访问。\n\n看上去很复杂，但事实上，由于我们并不需要了解容器内的服务具体在做些什么，理论上，我们只需要简单了解docker的工作原理以及`docker-compose.yml`和`nginx.conf`的配置规则即可实现前文提到的**一键部署**。\n\n当然，缺点也很明显：根域名（主页）和各二级域名（web服务）均需要通过nginx进行转发，且“处于一条绳上”，一旦nginx的配置或是其本身出现问题，所有写在配置里的服务就直接给一锅端了。\n\n~~当然这也契合部分人开（摸）发（鱼）习惯，很喜欢容器化开发者中流传的一句话：“我就喜欢配一天环境啥也不干的感觉☝🤓”~~\n\n两个配置文件的编写上，如果是单纯的多个二级域名的配置，网络上的教程一抓一大把，但我们的这个项目的难点就在于此，因为我们还要把先前就已成功部署的主页服务也融合进来，如何正确将它们配置到同一个端口上对于不熟悉docker和第一次接触nginx的人算的上是个挑战（比如我）。\n\n然而经过一段时间的尝试（AI+），我们就能发现这并非什么难事：\n\n#### docker配置\n\n以下配置模板仅供参考\n\n```yml\nversion: \"3.8\"\n\nservices:\n  remio-home:\n    image: kasuie/remio-home\n    container_name: remio-home\n    ports:\n      - \"8080:3000\"\n    environment:\n      - GTMID=.....\n      - PASSWORD=.....\n      - AMAP_KEY=.....\n    volumes:\n      - ./remio-home/config:/remio-home/config\n      - ./remio-home/icons:/remio-home/public/icons\n      - ./remio-home/fonts:/remio-home/public/fonts\n    networks:\n      - web_network\n    restart: unless-stopped\n\n  nginx:\n    image: nginx:latest\n    container_name: nginx\n    ports:\n      - \"80:80\"\n      # - \"443:443\"\n    volumes:\n      - ./nginx/conf.d/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/log:/var/log/nginx\n      # - ./certbot/www:/usr/share/certbot/www:ro\n      # - ./certbot/ssl:/etc/letsencrypt:ro\n    depends_on:\n      - subsite1\n      - subsite2\n      - subsite3\n    networks:\n      - web_network\n    command:  nginx -g 'daemon off;'\n\n  # certbot:\n  #   container_name: certbot\n  #   image: certbot/certbot\n  #   volumes:\n  #     - ./certbot/www:/usr/share/certbot/www:rw #http验证目录，可设置rw可写，与nginx容器对应的宿主机目录时一致的\n  #     - ./certbot/ssl:/etc/letsencrypt:rw #证书位置，同上，注意不要只映射到live，而是它的上一级\n\n  subsite1:\n    image: nginx:latest\n    container_name: subsite1\n    volumes:\n      - ./sub-sites/subsite1/public:/usr/share/nginx/html\n    networks:\n      - web_network\n\n  subsite2:\n    image: nginx:latest\n    container_name: subsite2\n    volumes:\n      - ./sub-sites/subsite2/public:/usr/share/nginx/html\n    networks:\n      - web_network\n\n  subsite3:\n    image: nginx:latest\n    container_name: subsite3\n    volumes:\n      - ./sub-sites/subsite3/public:/usr/share/nginx/html\n    networks:\n      - web_network\n\nnetworks:\n  web_network:\n    driver: bridge\n\n```\n\ndocker配置的关键在于`volumes`，即**挂载卷**的路径配置。\n\n在nginx附属服务（二级域名）的配置中，挂载卷参数的`:`前填入的是需要挂载的宿主机路径，`:`后是容器内的映射路径。这里我们需要挂载的路径是各个二级域名下需要“展示”的**前端文件**，即前文中提到的由静态网页生成工具生成的**静态资源**。\n\n在hexo中，我们通常使用命令`hexo cl && hexo g`清理旧版本的静态文件并生成新版，生成的静态文件默认处于各项目根目录的`public`路径下。\n\n静态资源的整理可在任意主机上进行，部署时只需确保由静态网页生成的静态资源处于服务器上并挂载到容器的正确路径下即可。通常情况下，为确保隐私安全，静态文件的整理工作我们一般在本地主机上进行。在后续的章节中我们会介绍如何通过配置Github Action实现使静态文件从本地自动化部署至服务器上。\n\n#### nginx配置\n\n`nginx.conf`的配置是该项目的核心，若出现错误导致部署无法进行，70%的问题出在nginx上，而nginx的问题有80%出在配置上（数据是瞎编的😋，但问题是真的）。\n\n以下是`nginx.conf`的参考配置，受限于篇幅，只列举主页及其中的一个二级域名的配置：\n\n```conf\nevents {}\n\nhttp {\n    ; server {\n    ;     listen 80;\n    ;     # listen [::]:80;\n\n    ;     server_name  virtualguard101.xyz;#域名\n    ;     server_tokens off;\n\n    ;     #配置http验证可访问\n    ;     location /.well-known/acme-challenge/ {\n    ;         #此目录都是nginx容器内的目录，对应宿主机volumes中的http验证目录，而宿主机的又与certbot容器中命令--webroot-path指定目录一致，从而就整个串起来了，解决了http验证问题\n    ;         root /usr/share/certbot/www;\n    ;     }\n    ;     #http跳转到https\n    ;     location / {\n    ;         return 301 https://$host$request_uri;\n    ;     }\n    ; }\n\n    server {\n        listen 80;\n        server_name virtualguard101.xyz;\n\n        location / {\n            proxy_pass http://remio-home:3000;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }       \n        # 强制HTTPS重定向\n        # return 301 https://$host$request_uri;\n    }\n\n    ; server {\n    ;     listen 443 ssl http2;\n    ;     server_name virtualguard101.xyz;\n\n    ;     ssl_certificate /etc/letsencrypt/live/virtualguard101.xyz/fullchain.pem;\n    ;     ssl_certificate_key /etc/letsencrypt/live/virtualguard101.xyz/privkey.pem;\n\n    ;     location / {\n    ;         proxy_pass http://remio-home:3000;\n    ;         proxy_set_header Host $host;\n    ;         proxy_set_header X-Real-IP $remote_addr;\n    ;         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    ;         proxy_set_header X-Forwarded-Proto $scheme;\n    ;     }\n    ; }\n\n\n    ; server {\n    ;     listen 80;\n    ;     # listen [::]:80;\n\n    ;     server_name  projects.virtualguard101.xyz;#域名\n    ;     server_tokens off;\n\n    ;     #配置http验证可访问\n    ;     location /.well-known/acme-challenge/ {\n    ;         #此目录都是nginx容器内的目录，对应宿主机volumes中的http验证目录，而宿主机的又与certbot容器中命令--webroot-path指定目录一致，从而就整个串起来了，解决了http验证问题\n    ;         root /usr/share/certbot/www;\n    ;     }\n    ;     #http跳转到https\n    ;     location / {\n    ;         return 301 https://$host$request_uri;\n    ;     }\n    ; }\n\n    server {\n        listen 80;\n\n        server_name projects.virtualguard101.xyz;\n\n        location / {\n            proxy_pass http://projects:80;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n\n        # return 301 https://$host$request_uri;\n    }\n\n  ;   server {\n  ;       listen 443 ssl http2;\n  ;       server_name projects.virtualguard101.xyz;\n\n  ;       ssl_certificate /etc/letsencrypt/live/projects.virtualguard101.xyz/fullchain.pem;\n  ;       ssl_certificate_key /etc/letsencrypt/live/projects.virtualguard101.xyz/privkey.pem;\n\n  ;       location / {\n  ;           proxy_pass http://projects:80;\n  ;           proxy_set_header Host $host;\n  ;           proxy_set_header X-Real-IP $remote_addr;\n  ;           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n  ;           proxy_set_header X-Forwarded-Proto $scheme;\n  ;       }\n  ;   }\n  }\n```\n\nnginx配置的关键在于反向代理转发的配置，这是nginx一个十分重要的特性，利用它能够实现nginx中许多核心功能，如负载均衡、websocket代理等。对于我们目前的项目需求，暂时无需使用到这些较为复杂的功能，我们现在只需弄明白参数`proxy_pass`具体是做什么的，以及其最为基础的配置规则，剩下的交给cv大法即可。\n\n在nginx配置中，`proxy_pass`用于将客户端的请求代理到指定的后段服务器，简单理解就是把请求作了一次转发。其基础语法如下：\n\n```conf\nlocation /path/ {\n    proxy_pass http://backend_server:port;\n}\n```\n\n该配置会将客户端上的请求转发至运行在`port`端口上名为`backend_server`的服务。结合上面的配置模板进行理解，我们可以发现主页服务在前面的docker配置中我们“恰好”将其配置在了容器的`3000`端口上，而其他的二级域名（nginx服务）我们均将其配置在了容器的`80`端口上，那么在外网设备（客户端）通过域名访问对应服务时，nginx就会将访问请求转发到对应的端口上。\n\n那么nginx怎么知道客户发送了访问请求？这就是**监听**要做的事。http服务默认通过`80`端口访问，通过配置`listen`参数我们可以使nginx服务监听`80`端口，就像饭点食堂阿姨站在特定窗口等着你去打饭一样。\n\n配置模板中注释掉的模块是https的配置，由于我们还未申请ssl证书，现在只能先使用http。关于ssl证书的申请我们也会在后续的章节介绍。\n\ndocker 与 nginx的配置完成后，我们便可通过`docker-compose up -d`命令进行服务部署，此时正常情况下网页已经可以通过外网设备访问。若出现问题，一般情况下会反映在各个服务容器上，可通过`docker-compose logs`命令查看日志信息。\n\n## Github Action自动化部署\n\n~~作为一个懒人~~为了提高效率，写个自动化配置把部署的工作交给计算机来做自然是个不错的方法。Github Action为我们提供了一个简单的自动化构建平台，通过模块化的配置和与git远程仓库结合的管理方式极大简化了配置难度，同时集成了版本控制。\n\nGithub Action自动化的配置通常位于子站点项目根目录的`.github/workflows`下。由于自动化部署的方式多种多样，配置自然也同理，故以下配置模板仅供参考。\n\n```yml\nname: Deploy Subsite\n\non:\n  push:\n    branches: [main]\n\njobs:\n  hexo-build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n        \n      - name: Setup Node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n          \n      - name: Install Dependencies\n        run: |\n          npm install -g hexo-cli\n          npm install\n        \n      - name: Build Site\n        run: hexo clean && hexo generate\n        \n      - name: Deploy to Server\n        uses: appleboy/scp-action@v0.1.7\n        with:\n          host: ${{ secrets.SERVER_IP }}\n          username: ${{ secrets.SERVER_USER }}\n          key: ${{ secrets.SSH_KEY }}\n          source: \"public/*\"\n          target: \"/home/<user>/sub-sites/<subsites_dir>/\"\n          \n      # - name: Refresh Nginx\n      #   uses: appleboy/ssh-action@v1.0.0\n      #   with:\n      #     host: ${{ secrets.SERVER_IP }}\n      #     username: ${{ secrets.SERVER_USER }}\n      #     key: ${{ secrets.SSH_KEY }}\n      #     script: |\n      #       docker exec nginx_main nginx -s reload\n```\n\n配置模板中，`Deploy to Server`模块是配置中较为核心的模块。该模块利用**scp**工具将生成的静态文件传送至站点服务器的指定路径下，其中的以`secrets`开头的三个变量分别是服务器的ip地址、用户与ssh私钥，通过仓库的`settings` >> `secrets and variables` >> `actions` 配置。\nssh私钥需在服务器上生成。\n\n通过上述自动化配置，在每次我们将本地仓库的更改推送至远程仓库时，github会自动在后台使用hexo生成静态文件，并通过scp将其发送至服务器的指定路径下。\n\n至此，我们仅需在本地的各个站点项目路径下修改配置或撰写文章，并将更改推送至github远程仓库，即可实现站点资源的自动化部署。\n\n## ssl认证与https模块配置（可选）\n\n经过上面五节的配置工作，我们的站点的雏形已经完成，接下来就是最后的收尾工作。关于ssl证书与https，尽管我们并不认为它是一个网页的必要组成部分，但我们还是强烈建议为自己的站点配置ssl证书与https模块以增强安全性与可扩展性。得益于[certbot](https://certbot.eff.org/)的ssl证书免费申请功能，我们已经能够较为容易地完成这项工作。\n\n### 首次申请ssl证书\n\n由于在该项目中，我们所有的服务均配置于docker容器中，因此我们同样需要将certbot的服务功能配置进docker-compose.yml中以实现后续的ssl证书自动化续签。事实上，certbot官方是不建议使用docker作为certbot的服务载体的，详情可参考[Get Certbot with Docker](https://eff-certbot.readthedocs.io/en/stable/install.html#alternative-1-docker)\n\n在配置前，首先需要拉取certbot的docker镜像：\n\n```bash\ndocker pull certbot/certbot\n```\n\n随后将前文中`docker-compose.yml`中`certbot`模块的注释去掉，并将nginx挂载卷中有关certbot的路径的注释去掉。启动服务，并通过以下命令进行测试申请：\n\n```bash\n# --dry-run是只测试不实际生成; --webroot-path对应着certbot内的http验证目录;-d后面是域名;--rm是运行后接着删除，certbot容器不需要一直开启，只是启动下生成证书即可\ndocker compose run --rm  certbot certonly --webroot --webroot-path /usr/share/certbot/www/ --dry-run -d [your_domain]\n```\n\n按照提示输入邮箱信息，若返回结果`The dry run was successful`，则说明测试成功，即可将`--dry-run`去掉以进行实际的证书获取：\n\n```bash\ndocker compose run --rm  certbot certonly --webroot --webroot-path /usr/share/certbot/www/ -d [your_domain]\n```\n\n申请成功后，可通过以下命令查看所有已申请的证书：\n\n```bash\ndocker compose run --rm certbot certificats\n```\n\n确认证书信息无误后即可开始nginx`https`模块的配置。与`docker-compose.yml`类似，将`nginx.conf`配置模板中https模块的注释去掉，同时将原来未注释的http模块注释掉，`docker-compose down && docker-compose up -d`重启服务。完成后通过外网设备访问网页，正常情况下，网址栏会显示该网页是安全的。\n\n### ssl证书自动化续签\n\n使用certbot一个很大的原因就是因为其可通过配置**定时任务**进行ssl证书的自动化续签。具体配置十分简单，一个bash的问题：\n\n创建bash脚本，并写入定时申请命令：\n\n```bash\nvim sslrenew.sh   # 创建脚本文件\n\n# 写入命令\ndocker compose run certbot renew\n```\n\n`crontab -e`添加定时任务，每个月第一天凌晨四点执行，也可根据自己情况进行配置：\n\n```bash\n0 4 1 * * ~/sslrenew.sh\n```\n\n配置完成后，可通过`crontab -l`命令查看配置的定时命令，确认配置是否写入。\n\n**BASE END**\n\n到此为止，所有的基础配置也就完成了。此时我们的个人站点已经可以被世界上所有接入互联网的设备访问了，同时我们也可根据个人需求为站点添加各种各样的功能与服务。\n\n主要参考文献：\n- [docker部署nginx多级子域名 | 蓝易云](https://cloud.tsyidc.com/web/822.html)\n- [docker部署certbot与nginx来获取ssl证书添加https及自动更新 | vishun](https://www.cnblogs.com/vishun/p/15746849.html)\n- [使用Certbot自签SSL证书 | kasuie](https://kasuie.cc/article/22)\n\n---\n\n## 增添服务\n\n既然我们都选择了使用云服务器来构建我们的个人站点，那么仅使用它来存放静态页面显然是大材小用。对于站点功能的丰富，还是那句话，在成熟工具链丰富的现代开发环境下，并不是什么很难的事情。很多时候，我们只需要正确打开别人写好的文档即可。\n\n对于功能扩展这部分的内容，更多的还是将目光放在部署工具供应者的使用文档上，这里只基于该文介绍的站点部署方法简单介绍一下我个人摸索出的**标准化部署流程**以及部署过程中可能碰到的**问题**。\n\n### 标准化部署流程\n\n以下流程为个人在实际部署过程中摸索出的不同服务部署过程的共通点，仅供参考。\n\n现在，假设我们想要在服务器上部署一个AI对话服务，那么我们便可遵循以下流程进行服务的配置及部署：\n\n#### 一、工具链选取及基础配置工作\n\n- **0. 选取对应的服务部署工具链，查阅官方文档并结合当前环境分析部署可行性。**\n\n我们想要在服务器上部署一个AI对话服务，那么结合当前部署环境，我们就应该在网络上查找对应的`docker`镜像（image）。这里我们使用[LLM Frontend | SillyTavern](https://github.com/SillyTavern/SillyTavern)进行部署。\n\n该框架具有docker镜像，且支持使用docker-compose部署，符合当前的环境要求，且部署难度和成本相对较低。\n\n- **1. 拉取docker镜像（可跳过）**\n\n执行以下命令以获取待部署的docker镜像：\n\n```bash\ndocker pull ghcr.io/sillytavern/sillytavern:latest\n```\n\n在使用docker-compose进行部署时，若`docker-compose.yml`配置无误，镜像会自动拉取。执行这一步主要是为了提前判定镜像是否处于可获取的状态。\n\n- **2. 根据工具文档及个人需求进行配置文件的配置或修改**\n\n项目主页：[SillyTavern - LLM Frontend for Power User](https://sillytavern.app/)\n项目仓库：[SillyTavern](https://github.com/SillyTavern/SillyTavern)\n\n#### 二、docker-compose.yml配置\n\n由于docker的容器环境是我们站点的部署基础，这部分的配置便显得尤为重要。可参考以下步骤进行配置：\n\n- **1. 依照文档给出的配置框架结合部署环境进行基础配置**\n\n官方给出的`docker-compose.yml`如下：\n\n```yml\nservices:\n  sillytavern:\n    build: ..\n    container_name: sillytavern\n    hostname: sillytavern\n    image: ghcr.io/sillytavern/sillytavern:latest\n    environment:\n      - NODE_ENV=production\n      - FORCE_COLOR=1\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - \"./config:/home/node/app/config\"\n      - \"./data:/home/node/app/data\"\n      - \"./plugins:/home/node/app/plugins\"\n      - \"./extensions:/home/node/app/public/scripts/extensions/third-party\"\n    restart: unless-stopped\n```\n\n我们可结合部署环境与部署需求对`environment`、`volumes`、`port`中的值进行修改，同时还需注意`docker-compose.yml`与服务自身配置（`config.yaml`）的对应关系。比如，针对`port`参数，`config.yaml`中默认将服务映射在`8000`端口上，若两个配置不对应，在访问时就会遇到`502(Bad Gateway)`错误。\n\n还有一点需要注意：由于nginx服务也运行于容器中，故在此项目的实际配置与部署过程中，真正有效的端口参数是`port`参数的**容器服务端口**。\n\n- **2. 网络关系配置**\n\n容器化技术的一大亮点在于不同服务容器环境相互独立的情况下也可通过形形色色的配置建立起各个容器间的联系。配置这些东西过程被厌恶容器技术的人所诟病，这些人认为该过程徒增工作复杂度，殊不知这是被他们所忽略的本职工作。\n\n服务间网络关系的配置也是上述关系配置中的一环，通过前文的配置我们知道，各个服务的网络配置通过`networks`参数控制，而在该项目中我们统一使用`web_network`作为各个服务的网络配置参数。故在官方文档原有框架的基础上，我们需要为模块追加如下配置：\n\n```yml\nnetworks:\n  - web_network\n```\n\n<!-- 否则会导致sillytavern容器未连接到web_network网络，出现容器错误 -->\n\n- **3. 服务依赖关系**\n\n和网络关系相比，不同服务的依赖关系在体现各个服务容器之间的联系上更加直接。\n\n在本项目中，由于需要使用nginx对各个服务进行转发，依赖关系便体现在各个部署在二级域名上的服务与nginx服务上。完成`sillytavern`服务的配置后，我们需要在nginx模块的`depend_on`参数追加如下配置：\n\n```yml\ndepend_on:\n  - .....\n  - sillytavern\n```\n\n<!--显式声明容器依赖关系，确保sillytavern先于nginx启动，否则会出现nginx容器错误 -->\n\n#### 三、nginx-https模块配置\n\n- **1. 反向代理基础配置（http模块）**\n\n依照前文基础配置的`nginx.conf`模板进行修改即可。\n\n- **2. ssl证书申请及https模块配置**\n\n遵循`复制模板`-`注释`-`解除注释`-`申请`-`解除注释`的“五步原则”。注释及解除注释操作的对应模块如下：\n\n**注释**：注释**http反向代理模块**  \n**第一次解除注释**：解除**http ACME验证挑战模块**注释  \n**第二次解除注释**：解除**https反向代理模块**注释\n\n--- \n完成以上三大步，8小步的配置与部署操作，部署工作基本也就完成了。\n\n## 常见问题\n\n部署过程中经常会碰到一些奇奇怪怪的问题，特别是不熟悉docker、nginx配置规则的初学者。下面是我在部署过程中遇到的问题的汇总。\n\n### nginx错误、服务访问错误\n\n通常表现为nginx容器无法正常运行，网页访问`500`、网页访问`502`等，具体原因可能有如下几种：\n\n- `nginx.conf`配置错误\n\n通常是反向代理模块中`proxy_pass`参数的配置有误，比如后端服务的**端口**或**服务名称**与`docker-compose.yml`中配置的不对应。\n\n- `docker-compose.yml`配置错误\n\n通常是前文提到的不同容器间关系的配置有误或者缺失，特别是nginx服务与其他需要通过nginx服务进行转发的服务之间的关系。如`networks`配置、容器依赖关系配置；以及前文提到的服务配置与docker-compose配置的对应关系问题，如服务端口的对应问题。\n\n### ssl证书申请（certbot）错误\n\n通常表现为无法申请ssl证书、申请证书后访问显示“~~https~~网页不安全”等，具体原因可能有如下几种：\n\n- 无法申请ssl证书（certbot无法正常运行）\n\n**1. 同一域名在短时间内申请次数过多**\n\n**2. `nginx.conf`中http ACME验证挑战模块配置有误**\n\n**3. 在特殊环境（如需要进行用户验证）下未注释http反向代理模块导致无法访问服务的问题（如`401`）**\n\n**4. 域名本身无法正常访问（`5xx`、`4xx`）**\n\n- 访问问题（提示网站不安全）\n\n**1. 申请ssl证书时信息有误，如二级域名名称错误**\n\n**2. `nginx.conf`中https模块二级域名（server_name）配置有误**\n\n**3. `nginx.conf`中https模块证书路径有误**\n\n关键在与证书与域名的对应关系是否有误。\n\n---\n**END**\n\n","tags":["web开发","docker"],"categories":["Projects"]},{"title":"Hello :)","url":"/2025/03/10/Hello/","content":"\nThis is the first content for my blog :) <br>\n\n![Hello](https://butterblock233.github.io/posts/images/Hello.gif) <br>\n\nGIF source: [Hello Apple by Meritt Thomas](https://dribbble.com/shots/17347386-Hello-Apple) <br>\n","categories":["test"]}]